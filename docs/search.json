[{"path":"https://cuny-epibios.github.io/PUBH614/CODE_OF_CONDUCT.html","id":null,"dir":"","previous_headings":"","what":"Contributor Code of Conduct","title":"Contributor Code of Conduct","text":"contributors maintainers project, pledge respect people contribute reporting issues, posting feature requests, updating documentation, submitting pull requests patches, activities. committed making participation project harassment-free experience everyone, regardless level experience, gender, gender identity expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion. Examples unacceptable behavior participants include use sexual language imagery, derogatory comments personal attacks, trolling, public private harassment, insults, unprofessional conduct. Project maintainers right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct. Project maintainers follow Code Conduct may removed project team. Instances abusive, harassing, otherwise unacceptable behavior may reported opening issue contacting one project maintainers. Code Conduct adapted Contributor Covenant, version 1.0.0, available .","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Attribution-ShareAlike 4.0 International","title":"Attribution-ShareAlike 4.0 International","text":"Creative Commons Corporation (“Creative Commons”) law firm provide legal services legal advice. Distribution Creative Commons public licenses create lawyer-client relationship. Creative Commons makes licenses related information available “-” basis. Creative Commons gives warranties regarding licenses, material licensed terms conditions, related information. Creative Commons disclaims liability damages resulting use fullest extent possible.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"using-creative-commons-public-licenses","dir":"","previous_headings":"","what":"Using Creative Commons Public Licenses","title":"Attribution-ShareAlike 4.0 International","text":"Creative Commons public licenses provide standard set terms conditions creators rights holders may use share original works authorship material subject copyright certain rights specified public license . following considerations informational purposes , exhaustive, form part licenses. Considerations licensors: public licenses intended use authorized give public permission use material ways otherwise restricted copyright certain rights. licenses irrevocable. Licensors read understand terms conditions license choose applying . Licensors also secure rights necessary applying licenses public can reuse material expected. Licensors clearly mark material subject license. includes CC-licensed material, material used exception limitation copyright. considerations licensors. Considerations public: using one public licenses, licensor grants public permission use licensed material specified terms conditions. licensor’s permission necessary reason–example, applicable exception limitation copyright–use regulated license. licenses grant permissions copyright certain rights licensor authority grant. Use licensed material may still restricted reasons, including others copyright rights material. licensor may make special requests, asking changes marked described. Although required licenses, encouraged respect requests reasonable. considerations public.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"creative-commons-attribution-sharealike-40-international-public-license","dir":"","previous_headings":"","what":"Creative Commons Attribution-ShareAlike 4.0 International Public License","title":"Attribution-ShareAlike 4.0 International","text":"exercising Licensed Rights (defined ), accept agree bound terms conditions Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). extent Public License may interpreted contract, granted Licensed Rights consideration acceptance terms conditions, Licensor grants rights consideration benefits Licensor receives making Licensed Material available terms conditions.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-1--definitions","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 1 – Definitions.","title":"Attribution-ShareAlike 4.0 International","text":"Adapted Material means material subject Copyright Similar Rights derived based upon Licensed Material Licensed Material translated, altered, arranged, transformed, otherwise modified manner requiring permission Copyright Similar Rights held Licensor. purposes Public License, Licensed Material musical work, performance, sound recording, Adapted Material always produced Licensed Material synched timed relation moving image. Adapter’s License means license apply Copyright Similar Rights contributions Adapted Material accordance terms conditions Public License. -SA Compatible License means license listed creativecommons.org/compatiblelicenses, approved Creative Commons essentially equivalent Public License. Copyright Similar Rights means copyright /similar rights closely related copyright including, without limitation, performance, broadcast, sound recording, Sui Generis Database Rights, without regard rights labeled categorized. purposes Public License, rights specified Section 2(b)(1)-(2) Copyright Similar Rights. Effective Technological Measures means measures , absence proper authority, may circumvented laws fulfilling obligations Article 11 WIPO Copyright Treaty adopted December 20, 1996, /similar international agreements. Exceptions Limitations means fair use, fair dealing, /exception limitation Copyright Similar Rights applies use Licensed Material. License Elements means license attributes listed name Creative Commons Public License. License Elements Public License Attribution ShareAlike. Licensed Material means artistic literary work, database, material Licensor applied Public License. Licensed Rights means rights granted subject terms conditions Public License, limited Copyright Similar Rights apply use Licensed Material Licensor authority license. Licensor means individual(s) entity(ies) granting rights Public License. Share means provide material public means process requires permission Licensed Rights, reproduction, public display, public performance, distribution, dissemination, communication, importation, make material available public including ways members public may access material place time individually chosen . Sui Generis Database Rights means rights copyright resulting Directive 96/9/EC European Parliament Council 11 March 1996 legal protection databases, amended /succeeded, well essentially equivalent rights anywhere world. means individual entity exercising Licensed Rights Public License. corresponding meaning.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-2--scope","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 2 – Scope.","title":"Attribution-ShareAlike 4.0 International","text":"License grant. Subject terms conditions Public License, Licensor hereby grants worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license exercise Licensed Rights Licensed Material : . reproduce Share Licensed Material, whole part; B. produce, reproduce, Share Adapted Material. Exceptions Limitations. avoidance doubt, Exceptions Limitations apply use, Public License apply, need comply terms conditions. Term. term Public License specified Section 6(). Media formats; technical modifications allowed. Licensor authorizes exercise Licensed Rights media formats whether now known hereafter created, make technical modifications necessary . Licensor waives /agrees assert right authority forbid making technical modifications necessary exercise Licensed Rights, including technical modifications necessary circumvent Effective Technological Measures. purposes Public License, simply making modifications authorized Section 2()(4) never produces Adapted Material. Downstream recipients. . Offer Licensor – Licensed Material. Every recipient Licensed Material automatically receives offer Licensor exercise Licensed Rights terms conditions Public License. B. Additional offer Licensor – Adapted Material. Every recipient Adapted Material automatically receives offer Licensor exercise Licensed Rights Adapted Material conditions Adapter’s License apply. C. downstream restrictions. may offer impose additional different terms conditions , apply Effective Technological Measures , Licensed Material restricts exercise Licensed Rights recipient Licensed Material. endorsement. Nothing Public License constitutes may construed permission assert imply , use Licensed Material , connected , sponsored, endorsed, granted official status , Licensor others designated receive attribution provided Section 3()(1)()(). rights. Moral rights, right integrity, licensed Public License, publicity, privacy, /similar personality rights; however, extent possible, Licensor waives /agrees assert rights held Licensor limited extent necessary allow exercise Licensed Rights, otherwise. Patent trademark rights licensed Public License. extent possible, Licensor waives right collect royalties exercise Licensed Rights, whether directly collecting society voluntary waivable statutory compulsory licensing scheme. cases Licensor expressly reserves right collect royalties.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-3--license-conditions","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 3 – License Conditions.","title":"Attribution-ShareAlike 4.0 International","text":"exercise Licensed Rights expressly made subject following conditions. Attribution. Share Licensed Material (including modified form), must: . retain following supplied Licensor Licensed Material: identification creator(s) Licensed Material others designated receive attribution, reasonable manner requested Licensor (including pseudonym designated); copyright notice; notice refers Public License; notice refers disclaimer warranties; URI hyperlink Licensed Material extent reasonably practicable; B. indicate modified Licensed Material retain indication previous modifications; C. indicate Licensed Material licensed Public License, include text , URI hyperlink , Public License. may satisfy conditions Section 3()(1) reasonable manner based medium, means, context Share Licensed Material. example, may reasonable satisfy conditions providing URI hyperlink resource includes required information. requested Licensor, must remove information required Section 3()(1)() extent reasonably practicable. ShareAlike. addition conditions Section 3(), Share Adapted Material produce, following conditions also apply. Adapter’s License apply must Creative Commons license License Elements, version later, -SA Compatible License. must include text , URI hyperlink , Adapter’s License apply. may satisfy condition reasonable manner based medium, means, context Share Adapted Material. may offer impose additional different terms conditions , apply Effective Technological Measures , Adapted Material restrict exercise rights granted Adapter’s License apply.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-4--sui-generis-database-rights","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 4 – Sui Generis Database Rights.","title":"Attribution-ShareAlike 4.0 International","text":"Licensed Rights include Sui Generis Database Rights apply use Licensed Material: avoidance doubt, Section 2()(1) grants right extract, reuse, reproduce, Share substantial portion contents database; include substantial portion database contents database Sui Generis Database Rights, database Sui Generis Database Rights (individual contents) Adapted Material, including purposes Section 3(b); must comply conditions Section 3() Share substantial portion contents database. avoidance doubt, Section 4 supplements replace obligations Public License Licensed Rights include Copyright Similar Rights.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-5--disclaimer-of-warranties-and-limitation-of-liability","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 5 – Disclaimer of Warranties and Limitation of Liability.","title":"Attribution-ShareAlike 4.0 International","text":"Unless otherwise separately undertaken Licensor, extent possible, Licensor offers Licensed Material --available, makes representations warranties kind concerning Licensed Material, whether express, implied, statutory, . includes, without limitation, warranties title, merchantability, fitness particular purpose, non-infringement, absence latent defects, accuracy, presence absence errors, whether known discoverable. disclaimers warranties allowed full part, disclaimer may apply . extent possible, event Licensor liable legal theory (including, without limitation, negligence) otherwise direct, special, indirect, incidental, consequential, punitive, exemplary, losses, costs, expenses, damages arising Public License use Licensed Material, even Licensor advised possibility losses, costs, expenses, damages. limitation liability allowed full part, limitation may apply . disclaimer warranties limitation liability provided shall interpreted manner , extent possible, closely approximates absolute disclaimer waiver liability.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-6--term-and-termination","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 6 – Term and Termination.","title":"Attribution-ShareAlike 4.0 International","text":"Public License applies term Copyright Similar Rights licensed . However, fail comply Public License, rights Public License terminate automatically. right use Licensed Material terminated Section 6(), reinstates: automatically date violation cured, provided cured within 30 days discovery violation; upon express reinstatement Licensor. avoidance doubt, Section 6(b) affect right Licensor may seek remedies violations Public License. avoidance doubt, Licensor may also offer Licensed Material separate terms conditions stop distributing Licensed Material time; however, terminate Public License. Sections 1, 5, 6, 7, 8 survive termination Public License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-7--other-terms-and-conditions","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 7 – Other Terms and Conditions.","title":"Attribution-ShareAlike 4.0 International","text":"Licensor shall bound additional different terms conditions communicated unless expressly agreed. arrangements, understandings, agreements regarding Licensed Material stated herein separate independent terms conditions Public License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/LICENSE.html","id":"section-8--interpretation","dir":"","previous_headings":"Creative Commons Attribution-ShareAlike 4.0 International Public License","what":"Section 8 – Interpretation.","title":"Attribution-ShareAlike 4.0 International","text":"avoidance doubt, Public License , shall interpreted , reduce, limit, restrict, impose conditions use Licensed Material lawfully made without permission Public License. extent possible, provision Public License deemed unenforceable, shall automatically reformed minimum extent necessary make enforceable. provision reformed, shall severed Public License without affecting enforceability remaining terms conditions. term condition Public License waived failure comply consented unless expressly agreed Licensor. Nothing Public License constitutes may interpreted limitation upon, waiver , privileges immunities apply Licensor , including legal processes jurisdiction authority. Creative Commons party public licenses. Notwithstanding, Creative Commons may elect apply one public licenses material publishes instances considered “Licensor.” text Creative Commons public licenses dedicated public domain CC0 Public Domain Dedication. Except limited purpose indicating material shared Creative Commons public license otherwise permitted Creative Commons policies published creativecommons.org/policies, Creative Commons authorize use trademark “Creative Commons” trademark logo Creative Commons without prior written consent including, without limitation, connection unauthorized modifications public licenses arrangements, understandings, agreements concerning use licensed material. avoidance doubt, paragraph form part public licenses. Creative Commons may contacted creativecommons.org.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"a-note-about-this-lab","dir":"Articles","previous_headings":"","what":"A note about this lab","title":"01. Introduction to R","text":"can also complete lab using Google Colab version version offers AI-powered features like code generation, explanation, error debugging. Jupyter notebook runs Google servers uses Google Drive storage. ’re viewing lab https://cuny-epibios.github.io/PUBH614/, can directly enter, edit, run R code web browser. Feel free experiment changing value assigned x trying different calculator-like commands.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"ai-powered-features-in-google-colab","dir":"Articles","previous_headings":"","what":"AI-Powered Features in Google Colab","title":"01. Introduction to R","text":"can also complete lab using Google Colab version version offers AI-powered features like code generation, explanation, error debugging. Jupyter notebook runs Google servers uses Google Drive storage.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"interactive-coding-in-your-web-browser","dir":"Articles","previous_headings":"","what":"Interactive Coding in Your Web Browser","title":"01. Introduction to R","text":"’re viewing lab https://cuny-epibios.github.io/PUBH614/, can directly enter, edit, run R code web browser. Feel free experiment changing value assigned x trying different calculator-like commands.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning Objectives","title":"01. Introduction to R","text":"end lab, able : Install load essential R packages (specifically openintro, dplyr, ggplot2). Understand use fundamental R syntax basic calculations variable assignment. Load inspect data frames using commands like typing data frame name glimpse(). Access work individual columns within data frame using $ operator. Perform vectorized operations R apply calculations across entire columns. Add new calculated columns data frame using dplyr function mutate(). Understand purpose syntax pipe operator (%>%). Create basic data visualizations, specifically scatter plots line plots, using ggplot2. Perform summary calculations data frames using dplyr function summarize(). Sort data frames based column values using dplyr function arrange(). Identify troubleshoot common errors R, including case sensitivity simple typos. Interpret basic trends patterns data visualizations summary statistics.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"loading-packages","dir":"Articles","previous_headings":"","what":"Loading packages","title":"01. Introduction to R","text":"Load packages library function. following line loads dplyr library, provides data manipulation functions use working environment, openintro package provides arbuthnot dataset used lab. Don’t worry warnings messages produces, aren’t important case. choosing use tidyverse package consists set packages necessary different aspects working data, anything loading data wrangling data visualizing data analyzing data. Additionally, packages share common philosophies designed work together. can find packages tidyverse tidyverse.org.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"dr--arbuthnots-baptism-records","dir":"Articles","previous_headings":"","what":"Dr. Arbuthnot’s Baptism Records","title":"01. Introduction to R","text":"get started, let’s take peek data. , can run code : placing cursor line pressing Ctrl-Enter Cmd-Enter placing cursor line pressing “Run” button upper right hand corner R Markdown file, clicking green arrow top right hand corner code chunk single line code included code chunk instructs R load data: Arbuthnot baptism counts boys girls. see Environment tab upper right hand corner RStudio window now lists data set called arbuthnot 82 observations 3 variables. interact R, create objects variety purposes. Sometimes load objects workspace loading package, done , sometimes create objects byproduct computation process, analysis performed, visualization created. Arbuthnot data set refers work Dr. John Arbuthnot, 18th century physician, writer, mathematician. interested ratio newborn boys newborn girls, gathered baptism records children born London every year 1629 1710. , can view data running code typing name dataset console. careful spelling capitalization use! R case sensitive, accidentally type Arbuthnot R tell object found. command display data us, however, printing whole dataset console useful. One advantage RStudio comes built-data viewer. Environment tab (upper right pane) lists objects environment. Clicking name arbuthnot open Data Viewer tab next R Markdown file, provides alternative display data set. display feel similar viewing data Excel, able scroll dataset inspect . However, unlike Excel, able edit data tab. done viewing data, can close tab clicking x upper left hand corner. inspecting data, see four columns numbers 82 rows. row represents different year Arbuthnot collected data. first entry row row number (index can use access data individual years want), second year, third fourth numbers boys girls baptized year, respectively. Use scrollbar right side console window examine complete data set. Note row numbers first column part Arbuthnot’s data. R adds row numbers part printout help make visual comparisons. can think index see left side spreadsheet. fact, comparison data spreadsheet generally helpful. R stored Arbuthnot’s data object similar spreadsheet table, R calls data frame. can see dimensions data frame well names variables first observations inserting name dataset glimpse() function, seen : Although previously said best practice type R code code chunk, better practice type command console. Generally, type code necessary solution code chunk. command used explore data, necessary solution code included solution file. can see 82 observations 3 variables dataset. variable names year, boys, girls. point, might notice many commands R look lot like functions math class; , invoking R commands means supplying function number inputs (called arguments) function uses produce output. glimpse() command, example, took single argument, name data frame produced display dataset output.","code":"Arbuthnot"},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"some-exploration","dir":"Articles","previous_headings":"","what":"Some Exploration","title":"01. Introduction to R","text":"Let’s start examine data little closely. can access data single column data frame extracting column $. example, code extracts boys column arbuthnot data frame. command show number boys baptized year. R interprets $ saying “go data frame comes , find variable comes .” command use extract just counts girls baptized? Try ! Notice way R printed data different. looked complete data frame, saw 82 rows, one line display. data extracted data frame, longer structured table variables. Instead, data displayed one right another. Objects print way called vectors; similar vectors seen mathematics courses, vectors represent list numbers. R added numbers displayed [brackets] along left side printout indicate entry’s location within vector. example, 5218 follows [1], indicating 5218 first entry vector. [43] displayed beginning line, indicate first number displayed line correspond 43rd entry vector.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"data-visualization","dir":"Articles","previous_headings":"","what":"Data visualization","title":"01. Introduction to R","text":"R powerful functions making graphics. use ggplot2 package create simple plot number girls baptized per year following code. code, use ggplot() function build plot. run code chunk, plot appear code chunk. R Markdown document displays plot code used generate , give idea plot look like final report. command also looks like mathematical function. time, however, function requires multiple inputs (arguments), separated commas. ggplot(): first argument always name dataset wish use plotting. Next, provide variables dataset assigned different aesthetic elements plot, x y axes. commands build blank plot, variables assigned x y axes. Next, need tell ggplot() type visualization like add blank template. add another layer ggplot() : adding + end line, indicate adding layer specify geometric object used create plot. Since want scatterplot, use geom_point(). tells ggplot() data point represented one point plot. wanted visualize plot using line graph instead scatterplot, replace geom_point() geom_line(). tells ggplot() draw line observation next observation (sequentially). Use plot address following question: apparent trend number girls baptized years? describe ? (ensure lab report comprehensive, sure include code needed make plot well written interpretation.) might wonder supposed know syntax ggplot() function. Thankfully, R documents functions extensively. learn function use (e.g. function’s arguments), just type question mark followed name function ’re interested console. Type following console: Notice help file comes forefront, replacing plot lower right panel. can toggle tabs clicking names.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"r-as-a-big-calculator","dir":"Articles","previous_headings":"","what":"R as a big calculator","title":"01. Introduction to R","text":"Now, suppose want plot total number baptisms. compute , use fact can use R big calculator. , can type mathematical expressions calculation console. calculation provide us total number baptisms 1629. repeat calculation year. probably take us , luckily faster way! add vector baptisms boys girls, R can compute sums simultaneously. see list 82 numbers. numbers appear list, working vectors rather data frame. number represents sum many boys girls baptized year. can take look first rows boys girls columns see calculation right.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"adding-a-new-variable-to-the-data-frame","dir":"Articles","previous_headings":"","what":"Adding a new variable to the data frame","title":"01. Introduction to R","text":"interested using new vector total number baptisms generate plots, ’ll want save permanent column data frame. can using following code: code lot new pieces , let’s break . first line two things, (1) adding new total column updated data frame, (2) overwriting existing arbuthnot data frame updated data frame includes new total column. able chain two processes together using piping (%>%) operator. piping operator takes output previous expression “pipes ” first argument next expression. continue analogy mathematical functions, x %>% f(y) equivalent f(x, y). Connecting arbuthnot mutate(total = boys + girls) pipe operator typing mutate(arbuthnot, total = boys + girls), arbuthnot becomes first argument included mutate() function. note piping: Note can read two lines code following: “Take arbuthnot dataset pipe mutate function. Mutate arbuthnot data set creating new variable called total sum variables called boys girls. assign resulting dataset object called arbuthnot, .e. overwrite old arbuthnot dataset new one containing new variable.” equivalent going row adding boys girls counts year recording value new column called total. new variable? can use ls() see contents environment: ’ll see now new column called total tacked onto data frame. special symbol <- performs assignment, taking output piping operations saving object environment. case, already object called arbuthnot environment, command updates data set new mutated column. See arbuthnot codebook. can make line plot total number baptisms per year following code: similar fashion, know total number baptisms boys girls 1629, can compute ratio number boys number girls baptized following code: Alternatively, calculate ratio every year acting complete boys girls columns, save calculations new variable named boy_to_girl_ratio: can also compute proportion newborns boys 1629 following code: can compute years simultaneously add new variable named boy_ratio dataset: Notice rather dividing boys + girls using total variable created earlier calculations! Now, generate plot proportion boys born time. see? Tip: use arrow keys console, can scroll previous commands, -called command history. can also access command history clicking history tab upper right panel. can save lot typing future. Finally, addition simple mathematical operators like subtraction division, can ask R make comparisons like greater , >, less , <, equality, ==. example, can create new variable called more_boys tells us whether number births boys outnumbered girls year following code: command adds new variable arbuthnot data frame containing values either TRUE year boys girls, FALSE year (answer may surprise ). variable contains different kind data encountered far. columns arbuthnot data frame values numerical (year, number boys girls). , ’ve asked R create logical data, data values either TRUE FALSE. general, data analysis involve many different kinds data types, one reason using R able represent compute many .","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"01. Introduction to R","text":"previous pages, recreated displays preliminary analysis Arbuthnot’s baptism data. assignment involves repeating steps, present day birth records United States. data stored data frame called present. find minimum maximum values columns, can use functions min() max() within summarize() call, learn following lab. ’s example find minimum maximum amount boy births year: Answer following questions present data frame: years included data set? dimensions data frame? variable (column) names? counts compare Arbuthnot’s? similar magnitude? Make plot displays proportion boys born time. see? Arbuthnot’s observation boys born greater proportion girls hold U.S.? Include plot response. Hint: able reuse code Exercise 3 , just replace name data frame. year see total number births U.S.? Hint: First calculate totals save new variable. , sort dataset descending order based total column. can interactively data viewer clicking arrows next variable names. include sorted result report need use two new functions. First use arrange() sorting variable. can arrange data descending order another function, desc(), descending order. sample code provided . data come reports Centers Disease Control. can learn bringing help file using command ?present.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/01_intro_to_r.html","id":"resources-for-learning-r","dir":"Articles","previous_headings":"","what":"Resources for learning R","title":"01. Introduction to R","text":"short introduction R, provide functions complete sense language course progresses. course using suite R packages tidyverse. book R Data Science Grolemund Wickham fantastic resource data analysis R tidyverse. Googling R code, make sure also include package names search query. example, instead Googling “scatterplot R”, Google “scatterplot R tidyverse”. may come handy throughout semester: Data transformation cheatsheet Data visualization cheatsheet Note code cheatsheets may advanced course. However majority become useful throughout semester. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"ai-powered-features-in-google-colab","dir":"Articles","previous_headings":"","what":"AI-Powered Features in Google Colab","title":"02. Introduction to Data","text":"can also complete lab using Google Colab version version offers AI-powered features like code generation, explanation, error debugging. end lab, able : Set Google Colab notebook run R code. Install load essential R packages (openintro, dplyr, ggplot2). Load datasets R environment (specifically, nycflights dataset). Understand basic structure data frame, including observations (rows) variables (columns). Inspect data frames using functions like names(), glimpse(), help operator ?. Subset data effectively using filter() single multiple logical conditions (e.g., ==, >, &, |). Calculate summary statistics (e.g., mean, median, IQR, count) datasets grouped data using summarise() group_by(). Create new variables add data frame using mutate() conditional logic ifelse(). Sort data frames based column values using arrange(). Histograms (geom_histogram()) understand distribution single numerical variable. Scatter plots (geom_point()) explore relationships two numerical variables. Bar plots (geom_bar()) visualize categorical data. Apply data manipulation visualization skills explore answer questions real-world data. Utilize R’s help features learn functions.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning Objectives","title":"02. Introduction to Data","text":"end lab, able : Set Google Colab notebook run R code. Install load essential R packages (openintro, dplyr, ggplot2). Load datasets R environment (specifically, nycflights dataset). Understand basic structure data frame, including observations (rows) variables (columns). Inspect data frames using functions like names(), glimpse(), help operator ?. Subset data effectively using filter() single multiple logical conditions (e.g., ==, >, &, |). Calculate summary statistics (e.g., mean, median, IQR, count) datasets grouped data using summarise() group_by(). Create new variables add data frame using mutate() conditional logic ifelse(). Sort data frames based column values using arrange(). Histograms (geom_histogram()) understand distribution single numerical variable. Scatter plots (geom_point()) explore relationships two numerical variables. Bar plots (geom_bar()) visualize categorical data. Apply data manipulation visualization skills explore answer questions real-world data. Utilize R’s help features learn functions.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"introduction-to-data","dir":"Articles","previous_headings":"","what":"Introduction to Data","title":"02. Introduction to Data","text":"define statistics field focuses turning information knowledge. first step process summarize describe raw information – data. lab explore flights, specifically random sample domestic flights departed three major New York City airports 2013. generate simple graphical numerical summaries data flights explore delay times. Since large data set, along way ’ll also learn indispensable skills data processing subsetting.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"02. Introduction to Data","text":"lab, explore visualize data using tidyverse suite packages. data can found companion package OpenIntro labs, openintro. Let’s load packages. Bureau Transportation Statistics (BTS) statistical agency part Research Innovative Technology Administration (RITA). name implies, BTS collects makes transportation data available, flights data working lab. First, ’ll view nycflights data frame. Type following console load data: data set nycflights shows workspace data matrix, row representing observation column representing variable. R calls data format data frame, term used throughout labs. data set, observation single flight. view names variables, type command returns names variables data frame. codebook (description variables) can accessed pulling help file: One variables refers carrier (.e. airline) flight, coded according following system. carrier: Two letter carrier abbreviation. 9E: Endeavor Air Inc. AA: American Airlines Inc. : Alaska Airlines Inc. B6: JetBlue Airways DL: Delta Air Lines Inc. EV: ExpressJet Airlines Inc. F9: Frontier Airlines Inc. FL: AirTran Airways Corporation HA: Hawaiian Airlines Inc. MQ: Envoy Air OO: SkyWest Airlines Inc. UA: United Air Lines Inc. US: US Airways Inc. VX: Virgin America WN: Southwest Airlines Co. YV: Mesa Airlines Inc. Remember can use glimpse take quick peek data understand contents better. nycflights data frame massive trove information. Let’s think questions might want answer data: delayed flights headed Los Angeles? departure delays vary month? three major NYC airports best time percentage departing flights?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"02. Introduction to Data","text":"lab, explore visualize data using tidyverse suite packages. data can found companion package OpenIntro labs, openintro. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"02. Introduction to Data","text":"Bureau Transportation Statistics (BTS) statistical agency part Research Innovative Technology Administration (RITA). name implies, BTS collects makes transportation data available, flights data working lab. First, ’ll view nycflights data frame. Type following console load data: data set nycflights shows workspace data matrix, row representing observation column representing variable. R calls data format data frame, term used throughout labs. data set, observation single flight. view names variables, type command returns names variables data frame. codebook (description variables) can accessed pulling help file: One variables refers carrier (.e. airline) flight, coded according following system. carrier: Two letter carrier abbreviation. 9E: Endeavor Air Inc. AA: American Airlines Inc. : Alaska Airlines Inc. B6: JetBlue Airways DL: Delta Air Lines Inc. EV: ExpressJet Airlines Inc. F9: Frontier Airlines Inc. FL: AirTran Airways Corporation HA: Hawaiian Airlines Inc. MQ: Envoy Air OO: SkyWest Airlines Inc. UA: United Air Lines Inc. US: US Airways Inc. VX: Virgin America WN: Southwest Airlines Co. YV: Mesa Airlines Inc. Remember can use glimpse take quick peek data understand contents better. nycflights data frame massive trove information. Let’s think questions might want answer data: delayed flights headed Los Angeles? departure delays vary month? three major NYC airports best time percentage departing flights?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"analysis","dir":"Articles","previous_headings":"","what":"Analysis","title":"02. Introduction to Data","text":"Let’s start examining distribution departure delays flights histogram. function says plot dep_delay variable nycflights data frame x-axis. also defines geom (short geometric object), describes type plot produce. Histograms generally good way see shape single distribution numerical data, shape can change depending data split different bins. can easily define binwidth want use: Look carefully three histograms. compare? features revealed one obscured another? want visualize delays flights headed Los Angeles, need first filter data flights destination (dest == \"LAX\") make histogram departure delays flights. Let’s decipher two commands (OK, might look like four lines, first two physical lines code actually part command. ’s common add break new line %>% help readability). Command 1: Take nycflights data frame, filter flights headed LAX, save result new data frame called lax_flights. == means “’s equal ”. LAX quotation marks since character string. Command 2: Basically ggplot call earlier making histogram, except uses smaller data frame flights headed LAX instead flights. Logical operators: Filtering certain observations (e.g. flights particular airport) often interest data frames might want examine observations certain characteristics separately rest data. , can use filter function series logical operators. commonly used logical operators data analysis follows: == means “equal ” != means “equal ” > < means “greater ” “less ” >= <= means “greater equal ” “less equal ” can also obtain numerical summaries flights: Note summarise function created list three different numerical summaries interested . names elements user defined, like mean_dd, median_dd, n, can customize names like (just don’t use spaces names). Calculating summary statistics also requires know function calls. Note n() reports sample size. Summary statistics: useful function calls summary statistics single numerical variable follows: mean median sd var IQR min max Note functions takes single vector argument returns single value. can also filter based multiple criteria. Suppose interested flights headed San Francisco (SFO) February: Note can separate conditions using commas want flights headed SFO February. interested either flights headed SFO February, can use | instead comma. Create new data frame includes flights headed SFO February, save data frame sfo_feb_flights. many flights meet criteria? Describe distribution arrival delays flights using histogram appropriate summary statistics. Hint: summary statistics use depend shape distribution. Another useful technique quickly calculating summary statistics various groups data frame. example, can modify command using group_by function get summary stats origin airport: , first grouped data origin calculated summary statistics. Calculate median interquartile range arr_delays flights sfo_feb_flights data frame, grouped carrier. carrier variable arrival delays? month expect highest average delay departing NYC airport? Let’s think answer question: First, calculate monthly averages departure delays. new language learning, group_by months, summarise mean departure delays. , arrange average delays descending order. Suppose really dislike departure delays want schedule travel month minimizes potential departure delay leaving NYC. One option choose month lowest mean departure delay. Another option choose month lowest median departure delay. pros cons two choices? Suppose flying NYC want know three major NYC airports best time departure rate departing flights. Also supposed , flight delayed less 5 minutes basically “time”. consider flight delayed 5 minutes “delayed”. order determine airport best time departure rate, can first classify flight “time” “delayed”, group flights origin airport, calculate time departure rates origin airport, finally arrange airports descending order time departure percentage. Let’s start classifying flight “time” “delayed” creating new variable mutate function. first argument mutate function name new variable want create, case dep_type. dep_delay < 5, classify flight \"time\" \"delayed\" , .e. flight delayed 5 minutes. Note also overwriting nycflights data frame new version data frame includes new dep_type variable. can handle remaining steps one code chunk: selecting airport simply based time departure percentage, NYC airport choose fly ? can also visualize distribution -time departure rate across three airports using segmented bar plot.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"departure-delays","dir":"Articles","previous_headings":"","what":"Departure delays","title":"02. Introduction to Data","text":"Let’s start examining distribution departure delays flights histogram. function says plot dep_delay variable nycflights data frame x-axis. also defines geom (short geometric object), describes type plot produce. Histograms generally good way see shape single distribution numerical data, shape can change depending data split different bins. can easily define binwidth want use: Look carefully three histograms. compare? features revealed one obscured another? want visualize delays flights headed Los Angeles, need first filter data flights destination (dest == \"LAX\") make histogram departure delays flights. Let’s decipher two commands (OK, might look like four lines, first two physical lines code actually part command. ’s common add break new line %>% help readability). Command 1: Take nycflights data frame, filter flights headed LAX, save result new data frame called lax_flights. == means “’s equal ”. LAX quotation marks since character string. Command 2: Basically ggplot call earlier making histogram, except uses smaller data frame flights headed LAX instead flights. Logical operators: Filtering certain observations (e.g. flights particular airport) often interest data frames might want examine observations certain characteristics separately rest data. , can use filter function series logical operators. commonly used logical operators data analysis follows: == means “equal ” != means “equal ” > < means “greater ” “less ” >= <= means “greater equal ” “less equal ” can also obtain numerical summaries flights: Note summarise function created list three different numerical summaries interested . names elements user defined, like mean_dd, median_dd, n, can customize names like (just don’t use spaces names). Calculating summary statistics also requires know function calls. Note n() reports sample size. Summary statistics: useful function calls summary statistics single numerical variable follows: mean median sd var IQR min max Note functions takes single vector argument returns single value. can also filter based multiple criteria. Suppose interested flights headed San Francisco (SFO) February: Note can separate conditions using commas want flights headed SFO February. interested either flights headed SFO February, can use | instead comma. Create new data frame includes flights headed SFO February, save data frame sfo_feb_flights. many flights meet criteria? Describe distribution arrival delays flights using histogram appropriate summary statistics. Hint: summary statistics use depend shape distribution. Another useful technique quickly calculating summary statistics various groups data frame. example, can modify command using group_by function get summary stats origin airport: , first grouped data origin calculated summary statistics. Calculate median interquartile range arr_delays flights sfo_feb_flights data frame, grouped carrier. carrier variable arrival delays?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"departure-delays-by-month","dir":"Articles","previous_headings":"","what":"Departure delays by month","title":"02. Introduction to Data","text":"month expect highest average delay departing NYC airport? Let’s think answer question: First, calculate monthly averages departure delays. new language learning, group_by months, summarise mean departure delays. , arrange average delays descending order. Suppose really dislike departure delays want schedule travel month minimizes potential departure delay leaving NYC. One option choose month lowest mean departure delay. Another option choose month lowest median departure delay. pros cons two choices?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"on-time-departure-rate-for-nyc-airports","dir":"Articles","previous_headings":"","what":"On time departure rate for NYC airports","title":"02. Introduction to Data","text":"Suppose flying NYC want know three major NYC airports best time departure rate departing flights. Also supposed , flight delayed less 5 minutes basically “time”. consider flight delayed 5 minutes “delayed”. order determine airport best time departure rate, can first classify flight “time” “delayed”, group flights origin airport, calculate time departure rates origin airport, finally arrange airports descending order time departure percentage. Let’s start classifying flight “time” “delayed” creating new variable mutate function. first argument mutate function name new variable want create, case dep_type. dep_delay < 5, classify flight \"time\" \"delayed\" , .e. flight delayed 5 minutes. Note also overwriting nycflights data frame new version data frame includes new dep_type variable. can handle remaining steps one code chunk: selecting airport simply based time departure percentage, NYC airport choose fly ? can also visualize distribution -time departure rate across three airports using segmented bar plot.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/02_intro_to_data.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"02. Introduction to Data","text":"Mutate data frame includes new variable contains average speed, avg_speed traveled plane flight (mph). Hint: Average speed can calculated distance divided number hours travel, note air_time given minutes. Make scatterplot avg_speed vs. distance. Describe relationship average speed distance. Hint: Use geom_point(). Create scatterplot. Hint: data frame plotted contains flights American Airlines, Delta Airlines, United Airlines, points colored carrier. create plot, determine (roughly) cutoff point departure delays can still expect get destination time. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"ai-powered-features-in-google-colab","dir":"Articles","previous_headings":"","what":"AI-Powered Features in Google Colab","title":"03. Probability","text":"can also complete lab using Google Colab version version offers AI-powered features like code generation, explanation, error debugging.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"learning-objectives","dir":"Articles","previous_headings":"","what":"Learning Objectives","title":"03. Probability","text":"end lab, able : Understand concepts independent dependent events probability. Learn simulate random events (e.g., coin flips, basketball shots) R. Use sample() function simulations, including specifying probabilities different outcomes. Understand purpose use set.seed() ensuring reproducibility simulations. Calculate shooting streak lengths sequence outcomes using calc_streak() function. Visualize distribution data, streak lengths, using geom_bar() ggplot2 package. Compare observed data (e.g., Kobe Bryant’s shooting streaks) simulated data (e.g., independent shooter model). Use comparisons make informal inferences whether observed patterns might due chance another underlying process (like “hot hand”).","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"the-hot-hand","dir":"Articles","previous_headings":"","what":"The Hot Hand","title":"03. Probability","text":"Basketball players make several baskets succession described hot hand. Fans players long believed hot hand phenomenon, refutes assumption shot independent next. However, 1985 paper Gilovich, Vallone, Tversky collected evidence contradicted belief showed successive shots independent events. paper started great controversy continues day, can see Googling hot hand basketball. expect resolve controversy today. However, lab ’ll apply one approach answering questions like . goals lab (1) think effects independent dependent events, (2) learn simulate shooting streaks R, (3) compare simulation actual data order determine hot hand phenomenon appears real.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"03. Probability","text":"lab, explore visualize data using tidyverse suite packages. data can found companion package OpenIntro labs, openintro. Let’s load packages. investigation focus performance one player: Kobe Bryant Los Angeles Lakers. performance Orlando Magic 2009 NBA Finals earned title Valuable Player many spectators commented appeared show hot hand. data file ’ll use called kobe_basket. data frame contains 133 observations 6 variables, every row records shot taken Kobe Bryant. shot variable dataset indicates whether shot hit (H) miss (M). Just looking string hits misses, can difficult gauge whether seems like Kobe shooting hot hand. One way can approach considering belief hot hand shooters tend go shooting streaks. lab, define length shooting streak number consecutive baskets made miss occurs. example, Game 1 Kobe following sequence hits misses nine shot attempts first quarter: H M | M | H H M | M | M | M \\textrm{H M | M | H H M | M | M | M} can verify viewing first 9 rows data data viewer. Within nine shot attempts, six streaks, separated “|” . lengths one, zero, two, zero, zero, zero (order occurrence). streak length 1 mean, .e. many hits misses streak 1? streak length 0? Counting streak lengths manually 133 shots get tedious, ’ll use custom function openintro library, calc_streak, calculate store results data frame called kobe_streak length variable. can take look distribution streak lengths. Describe distribution Kobe’s streak lengths 2009 NBA finals. typical streak length? long longest streak baskets? Make sure include accompanying plot answer.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"03. Probability","text":"lab, explore visualize data using tidyverse suite packages. data can found companion package OpenIntro labs, openintro. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"03. Probability","text":"investigation focus performance one player: Kobe Bryant Los Angeles Lakers. performance Orlando Magic 2009 NBA Finals earned title Valuable Player many spectators commented appeared show hot hand. data file ’ll use called kobe_basket. data frame contains 133 observations 6 variables, every row records shot taken Kobe Bryant. shot variable dataset indicates whether shot hit (H) miss (M). Just looking string hits misses, can difficult gauge whether seems like Kobe shooting hot hand. One way can approach considering belief hot hand shooters tend go shooting streaks. lab, define length shooting streak number consecutive baskets made miss occurs. example, Game 1 Kobe following sequence hits misses nine shot attempts first quarter: H M | M | H H M | M | M | M \\textrm{H M | M | H H M | M | M | M} can verify viewing first 9 rows data data viewer. Within nine shot attempts, six streaks, separated “|” . lengths one, zero, two, zero, zero, zero (order occurrence). streak length 1 mean, .e. many hits misses streak 1? streak length 0? Counting streak lengths manually 133 shots get tedious, ’ll use custom function openintro library, calc_streak, calculate store results data frame called kobe_streak length variable. can take look distribution streak lengths. Describe distribution Kobe’s streak lengths 2009 NBA finals. typical streak length? long longest streak baskets? Make sure include accompanying plot answer.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"compared-to-what","dir":"Articles","previous_headings":"","what":"Compared to What?","title":"03. Probability","text":"’ve shown Kobe long shooting streaks, long enough support belief hot hand? can compare ? answer questions, let’s return idea independence. Two processes independent outcome one process doesn’t effect outcome second. shot player takes independent process, made missed first shot affect probability make miss second shot. shooter hot hand shots independent one another. Specifically, shooter makes first shot, hot hand model says higher probability making second shot. Let’s suppose moment hot hand model valid Kobe. career, percentage time Kobe makes basket (.e. shooting percentage) 45%, probability notation, P(shot 1 = H)=0.45 P(\\textrm{shot 1 = H}) = 0.45 makes first shot hot hand (independent shots), probability makes second shot go , let’s say, 60%, P(shot 2 = H|shot 1 = H)=0.60 P(\\textrm{shot 2 = H} \\, | \\, \\textrm{shot 1 = H}) = 0.60 result increased probabilities, ’d expect Kobe longer streaks. Compare skeptical perspective Kobe hot hand, shot independent next. hit first shot, probability makes second still 0.45. P(shot 2 = H|shot 1 = H)=0.45 P(\\textrm{shot 2 = H} \\, | \\, \\textrm{shot 1 = H}) = 0.45 words, making first shot nothing effect probability ’d make second shot. Kobe’s shots independent, ’d probability hitting every shot regardless past shots: 45%. Now ’ve phrased situation terms independent shots, let’s return question: tell Kobe’s shooting streaks long enough indicate hot hand? can compare streak lengths someone without hot hand: independent shooter.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"simulations-in-r","dir":"Articles","previous_headings":"","what":"Simulations in R","title":"03. Probability","text":"don’t data shooter know independent shots, sort data easy simulate R. simulation, set ground rules random process computer uses random numbers generate outcome adheres rules. simple example, can simulate flipping fair coin following. vector coin_outcomes can thought hat two slips paper : one slip says heads says tails. function sample draws one slip hat tells us head tail. Run second command listed several times. Just like flipping coin, sometimes ’ll get heads, sometimes ’ll get tails, long run, ’d expect get roughly equal numbers . wanted simulate flipping fair coin 100 times, either run function 100 times , simply, adjust size argument, governs many samples draw (replace = TRUE argument indicates put slip paper back hat drawing ). Save resulting vector heads tails new object called sim_fair_coin. view results simulation, type name object use table count number heads tails. Since two elements coin_outcomes, probability “flip” coin lands heads 0.5. Say ’re trying simulate unfair coin know lands heads 20% time. can adjust adding argument called prob, provides vector two probability weights. prob=c(0.2, 0.8) indicates two elements outcomes vector, want select first one, heads, probability 0.2 second one, tails probability 0.8. Another way thinking think outcome space bag 10 chips, 2 chips labeled “head” 8 chips “tail”. Therefore draw, probability drawing chip says “head”” 20%, “tail” 80%. simulation flipping unfair coin 100 times, many flips came heads? Include code sampling unfair coin response. Since markdown file run code, generate new sample time Knit , also “set seed” sample. Read setting seed . note setting seed: Setting seed cause R select sample time knit document. make sure results don’t change time knit, also ensure reproducibility work (setting seed possible reproduce results). can set seed like : number completely arbitraty. need inspiration, can use ID, birthday, just random string numbers. important thing use seed document. Remember sample exercise . sense, ’ve shrunken size slip paper says “heads”, making less likely drawn, ’ve increased size slip paper saying “tails”, making likely drawn. simulated fair coin, slips paper size. happens default don’t provide prob argument; elements outcomes vector equal probability drawn. want learn sample function, recall can always check help file.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"simulating-the-independent-shooter","dir":"Articles","previous_headings":"","what":"Simulating the Independent Shooter","title":"03. Probability","text":"Simulating basketball player independent shots uses mechanism used simulate coin flip. simulate single shot independent shooter shooting percentage 50% can type make valid comparison Kobe simulated independent shooter, need align shooting percentage number attempted shots. change needs made sample function reflects shooting percentage 45%? Make adjustment, run simulation sample 133 shots. Assign output simulation new object called sim_basket. Note ’ve named new vector sim_basket, name gave previous vector reflecting shooting percentage 50%. situation, R overwrites old object new one, always make sure don’t need information old vector reassigning name. results simulation saved sim_basket, data necessary compare Kobe independent shooter. data sets represent results 133 shot attempts, shooting percentage 45%. know simulated data shooter independent shots. , know simulated shooter hot hand.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"03. Probability","text":"Using calc_streak, compute streak lengths sim_basket, save results data frame called sim_streak. Describe distribution streak lengths. typical streak length simulated independent shooter 45% shooting percentage? long player’s longest streak baskets 133 shots? Make sure include plot answer. run simulation independent shooter second time, expect streak distribution compare distribution question ? Exactly ? Somewhat similar? Totally different? Explain reasoning. Kobe Bryant’s distribution streak lengths compare distribution streak lengths simulated shooter? Using comparison, evidence hot hand model fits Kobe’s shooting patterns? Explain. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/03_probability.html","id":"comparing-kobe-bryant-to-the-independent-shooter","dir":"Articles","previous_headings":"","what":"Comparing Kobe Bryant to the Independent Shooter","title":"03. Probability","text":"Using calc_streak, compute streak lengths sim_basket, save results data frame called sim_streak. Describe distribution streak lengths. typical streak length simulated independent shooter 45% shooting percentage? long player’s longest streak baskets 133 shots? Make sure include plot answer. run simulation independent shooter second time, expect streak distribution compare distribution question ? Exactly ? Somewhat similar? Totally different? Explain reasoning. Kobe Bryant’s distribution streak lengths compare distribution streak lengths simulated shooter? Using comparison, evidence hot hand model fits Kobe’s shooting patterns? Explain. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"04. The normal distribution","text":"lab, explore visualize data using tidyverse suite packages well openintro package. Let’s load packages. week ’ll working fast food data. data set contains data 515 menu items popular fast food restaurants worldwide. Let’s take quick peek first rows data. Either can use glimpse like , head . ’ll see every observation 17 measurements, many nutritional facts. ’ll focusing just three columns get started: restaurant, calories, calories fat. Let’s first focus just products McDonalds Dairy Queen. Make plot (plots) visualize distributions amount calories fat options two restaurants. centers, shapes, spreads compare?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"04. The normal distribution","text":"lab, explore visualize data using tidyverse suite packages well openintro package. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"04. The normal distribution","text":"week ’ll working fast food data. data set contains data 515 menu items popular fast food restaurants worldwide. Let’s take quick peek first rows data. Either can use glimpse like , head . ’ll see every observation 17 measurements, many nutritional facts. ’ll focusing just three columns get started: restaurant, calories, calories fat. Let’s first focus just products McDonalds Dairy Queen. Make plot (plots) visualize distributions amount calories fat options two restaurants. centers, shapes, spreads compare?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"the-normal-distribution","dir":"Articles","previous_headings":"","what":"The normal distribution","title":"04. The normal distribution","text":"description distributions, use words like bell-shaped normal? ’s tempting say faced unimodal symmetric distribution. see accurate description , can plot normal distribution curve top histogram see closely data follow normal distribution. normal curve mean standard deviation data. ’ll focusing calories fat Dairy Queen products, let’s store separate object calculate statistics referenced later. Next, make density histogram use backdrop use lines function overlay normal probability curve. difference frequency histogram density histogram frequency histogram heights bars add total number observations, density histogram areas bars add 1. area bar can calculated simply height times width bar. Using density histogram allows us properly overlay normal distribution curve histogram since curve normal probability density function also area curve 1. Frequency density histograms display exact shape; differ y-axis. can verify comparing frequency histogram constructed earlier density histogram created commands . initializing blank plot geom_blank(), ggplot2 package (within tidyverse) allows us add additional layers. first layer density histogram. second layer statistical function – density normal curve, dnorm. specify want curve mean standard deviation column calories fat. argument col simply sets color line drawn. left , line drawn black. Based plot, appear data follow nearly normal distribution?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"evaluating-the-normal-distribution","dir":"Articles","previous_headings":"","what":"Evaluating the normal distribution","title":"04. The normal distribution","text":"Eyeballing shape histogram one way determine data appear nearly normally distributed, can frustrating decide just close histogram curve. alternative approach involves constructing normal probability plot, also called normal Q-Q plot “quantile-quantile”. time, can use geom_line() layer, specifying creating Q-Q plot stat argument. ’s important note , instead using x instead aes(), need use sample. x-axis values correspond quantiles theoretically normal curve mean 0 standard deviation 1 (.e., standard normal distribution). y-axis values correspond quantiles original unstandardized sample data. However, even standardize sample data values, Q-Q plot look identical. data set nearly normal result probability plot points closely follow diagonal line. deviations normality leads deviations points line. plot Dairy Queen’s calories fat shows points tend follow line errant points towards upper tail. ’re left problem encountered histogram : close close enough? useful way address question rephrase : probability plots look like data know came normal distribution? can answer simulating data normal distribution using rnorm. first argument indicates many numbers ’d like generate, specify number menu items dairy_queen data set using nrow() function. last two arguments determine mean standard deviation normal distribution simulated sample generated. can take look shape simulated data set, sim_norm, well normal probability plot. Make normal probability plot sim_norm. points fall line? plot compare probability plot real data? (Since sim_norm dataframe, can put directly sample argument data argument can dropped.) Even better comparing original plot single plot generated normal distribution compare many plots using following function. shows Q-Q plot corresponding original data top left corner, Q-Q plots 8 different simulated normal data. may helpful click zoom button plot window. Note: can use double colon :: tell R explicitly package use function. necessary case specify function qqnormsim comes openintro package, openintro package already loaded. two packages define functions name, can use :: tell R (anyone reading code) package function want use comes . load two packages define functions name, second package loaded “mask” function first, without use ::, function last package loaded take precedent. common example select function, defined base R dplyr library, load library(dplyr), definition select replaces defined base R. normal probability plot calories fat look similar plots created simulated data? , plots provide evidence calories fat nearly normal? Using technique, determine whether calories McDonald’s menu appear come normal distribution.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"normal-probabilities","dir":"Articles","previous_headings":"","what":"Normal probabilities","title":"04. The normal distribution","text":"Okay, now slew tools judge whether variable normally distributed. care? turns statisticians know lot normal distribution. decide random variable approximately normal, can answer sorts questions variable related probability. Take, example, question , “probability randomly chosen Dairy Queen product 600 calories fat?” assume calories fat Dairy Queen’s menu normally distributed (close approximation also okay), can find probability calculating Z score consulting Z table (also called normal probability table). R, done one step function pnorm(). Note function pnorm() gives area normal curve given value, q, given mean standard deviation. Since ’re interested probability Dairy Queen item 600 calories fat, take one minus probability. Assuming normal distribution allowed us calculate theoretical probability. want calculate probability empirically, simply need determine many observations fall 600 divide number total sample size. Although probabilities exactly , reasonably close. closer distribution normal, accurate theoretical probabilities . Write two probability questions like answer restaurants dataset. Calculate probabilities using theoretical normal distribution well empirical distribution (four probabilities ). one closer agreement two methods?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04_normal_distribution.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"04. The normal distribution","text":"Now let’s consider variables dataset. different restaurants, ones’ distribution closest normal sodium? Note normal probability plots sodium distributions seem stepwise pattern. think might case? can see, normal probability plots can used assess normality visualize skewness. Make normal probability plot total carbohydrates restaurant choice. Based normal probability plot, variable left skewed, symmetric, right skewed? Use histogram confirm findings. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"04b. Logistic regression","text":"lab load Small-cell Lung Cancer dataset (see codebook). working files R, ’s important know working directory , file want load . lab uses webR/WASM, runs web browser isolated computer’s filesystem. ’ll see R session empty directory exists session otherwise computer. use commands running R computer, see directories files file explorer. Since webR/WASM filesystem isolated local filesystem, ’ll use download.file() download dataset web, instead clicking web browser. use Dropbox etc create downloadable URL another file want use. Datasets PUBH614 labs kept https://github.com/CUNY-epibios/PUBH614/tree/main/datasets. clicking dataset, sure press “Raw” button get URL raw dataset, opposed HTML page displaying . dataset, https://raw.githubusercontent.com/CUNY-epibios/PUBH614/refs/heads/main/datasets/Stats4-%20more.csv. destfile argument specifies filename use downloaded file. Check now file downloaded: readr provides read_csv, powerful version base-R read.csv function. using RStudio, “File - Import Dataset” option provides much simplified way find datasets local filesystem import - see .","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"smoking-and-lung-cancer-analysis","dir":"Articles","previous_headings":"","what":"Smoking and Lung Cancer Analysis","title":"04b. Logistic regression","text":"functions read_xlsx types excel sheets. Use glimpse see ’s : Compare slide 8 session 4: coefficients log odds, exponentiate get odds ratio smoking lung cancer: Note now adjusted sex. demonstrates estimating odds ratios suitable two--two table gives answer using logistic regression, logistic regression much easier use, particularly adjusting confounders. However, need data right format - , row person smoking status, lung cancer status, sex.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"cross-tabulation-of-smoking-and-lung-cancer","dir":"Articles","previous_headings":"","what":"Cross-tabulation of Smoking and Lung Cancer","title":"04b. Logistic regression","text":"Compare slide 8 session 4:","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"logistic-regression-analysis","dir":"Articles","previous_headings":"","what":"Logistic Regression Analysis","title":"04b. Logistic regression","text":"coefficients log odds, exponentiate get odds ratio smoking lung cancer: Note now adjusted sex. demonstrates estimating odds ratios suitable two--two table gives answer using logistic regression, logistic regression much easier use, particularly adjusting confounders. However, need data right format - , row person smoking status, lung cancer status, sex.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"basic-model-smoking-and-lung-cancer","dir":"Articles","previous_headings":"Smoking and Lung Cancer Analysis","what":"Basic Model: Smoking and Lung Cancer","title":"04b. Logistic regression","text":"coefficients log odds, exponentiate get odds ratio smoking lung cancer:","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"adjusted-model-smoking-lung-cancer-and-sex","dir":"Articles","previous_headings":"Smoking and Lung Cancer Analysis","what":"Adjusted Model: Smoking, Lung Cancer, and Sex","title":"04b. Logistic regression","text":"Note now adjusted sex.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"sex-specific-estimates","dir":"Articles","previous_headings":"Smoking and Lung Cancer Analysis","what":"Sex-specific Estimates","title":"04b. Logistic regression","text":"demonstrates estimating odds ratios suitable two--two table gives answer using logistic regression, logistic regression much easier use, particularly adjusting confounders. However, need data right format - , row person smoking status, lung cancer status, sex.","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"analysis-for-women","dir":"Articles","previous_headings":"Smoking and Lung Cancer Analysis","what":"Analysis for Women","title":"04b. Logistic regression","text":"demonstrates estimating odds ratios suitable two--two table gives answer using logistic regression, logistic regression much easier use, particularly adjusting confounders. However, need data right format - , row person smoking status, lung cancer status, sex.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"job-callback-analysis","dir":"Articles","previous_headings":"","what":"Job Callback Analysis","title":"04b. Logistic regression","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"experience-analysis","dir":"Articles","previous_headings":"","what":"Experience Analysis","title":"04b. Logistic regression","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"experience-effect-by-demographics","dir":"Articles","previous_headings":"Job Callback Analysis","what":"Experience Effect by Demographics","title":"04b. Logistic regression","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/04b_logistic.html","id":"for-female-candidates","dir":"Articles","previous_headings":"Job Callback Analysis","what":"For Female Candidates","title":"04b. Logistic regression","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"05a. Foundations for statistical inference - Sampling distributions","text":"lab, explore visualize data using tidyverse suite packages. also use infer package resampling. Let’s load packages. 2019 Gallup report states following: premise scientific progress benefits people embodied discoveries throughout ages – development vaccinations explosion technology past decades, resulting billions supercomputers now resting hands pockets people worldwide. Still, everyone around world feels science benefits personally. Source: World Science Day: Knowledge Power? Wellcome Global Monitor finds 20% people globally believe work scientists benefits people like . lab, assume 20% true population proportion learn sample proportions can vary sample sample taking smaller samples population. first create population assuming population size 100,000. means 20,000 (20%) population think work scientists benefit personally remaining 80,000 think . name data frame global_monitor name variable contains responses question “believe work scientists benefit people like ?” scientist_work. can quickly visualize distribution responses using bar plot. can also obtain summary statistics confirm constructed data frame correctly.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"05a. Foundations for statistical inference - Sampling distributions","text":"lab, explore visualize data using tidyverse suite packages. also use infer package resampling. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"05a. Foundations for statistical inference - Sampling distributions","text":"2019 Gallup report states following: premise scientific progress benefits people embodied discoveries throughout ages – development vaccinations explosion technology past decades, resulting billions supercomputers now resting hands pockets people worldwide. Still, everyone around world feels science benefits personally. Source: World Science Day: Knowledge Power? Wellcome Global Monitor finds 20% people globally believe work scientists benefits people like . lab, assume 20% true population proportion learn sample proportions can vary sample sample taking smaller samples population. first create population assuming population size 100,000. means 20,000 (20%) population think work scientists benefit personally remaining 80,000 think . name data frame global_monitor name variable contains responses question “believe work scientists benefit people like ?” scientist_work. can quickly visualize distribution responses using bar plot. can also obtain summary statistics confirm constructed data frame correctly.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"the-unknown-sampling-distribution","dir":"Articles","previous_headings":"","what":"The unknown sampling distribution","title":"05a. Foundations for statistical inference - Sampling distributions","text":"lab, access entire population, rarely case real life. Gathering information entire population often extremely costly impossible. , often take sample population use understand properties population. interested estimating proportion people don’t think work scientists benefits , can use sample_n command survey population. command collects simple random sample size 50 global_monitor dataset, assigns result samp1. similar randomly drawing names hat contains names population. Working 50 names considerably simpler working 100,000 people population. Describe distribution responses sample. compare distribution responses population. Hint: Although sample_n function takes random sample observations (.e. rows) dataset, can still refer variables dataset names. Code presented earlier visualizing summarising population data still useful sample, however careful label proportion p since ’re now calculating sample statistic, population parameters. can customize label statistics indicate comes sample. ’re interested estimating proportion people believe work scientists benefits , access population data, best single guess sample proportion. Depending 50 people selected, estimate bit bit true population proportion 80%. general, though, sample proportion turns pretty good estimate true population proportion, able get sampling less 1% population. expect sample proportion match sample proportion another student’s sample? , ? answer , expect proportions somewhat different different? Take second sample, also size 50, call samp2. sample proportion samp2 compare samp1? Suppose took two samples, one size 100 one size 1000. think provide accurate estimate population proportion? surprisingly, every time take another random sample, might get different sample proportion. ’s useful get sense just much variability expect estimating population mean way. distribution sample proportions, called sampling distribution (proportion), can help understand variability. lab, access population, can build sampling distribution sample proportion repeating steps many times. , use R take 15,000 different samples size 50 population, calculate proportion responses sample, filter Doesn’t benefit responses, store result vector called sample_props50. Note specify replace = TRUE since sampling distributions constructed sampling replacement. can visualize distribution proportions histogram. Next, review set code works. many elements sample_props50? Describe sampling distribution, sure specifically note center. Make sure include plot distribution answer.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"interlude-sampling-distributions","dir":"Articles","previous_headings":"","what":"Interlude: Sampling distributions","title":"05a. Foundations for statistical inference - Sampling distributions","text":"idea behind rep_sample_n function repetition. Earlier, took single sample size n (50) population people population. new function, can repeat sampling procedure rep times order build distribution series sample statistics, called sampling distribution. Note practice one rarely gets build true sampling distributions, one rarely access data entire population. Without rep_sample_n function, painful. manually run following code 15,000 times well store resulting sample proportions time separate vector. Note 15,000 times computed proportion, different sample! make sure understand sampling distributions built, exactly rep_sample_n function , try modifying code create sampling distribution 25 sample proportions samples size 10, put data frame named sample_props_small. Print output. many observations object called sample_props_small? observation represent?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"sample-size-and-the-sampling-distribution","dir":"Articles","previous_headings":"","what":"Sample size and the sampling distribution","title":"05a. Foundations for statistical inference - Sampling distributions","text":"Mechanics aside, let’s return reason used rep_sample_n function: compute sampling distribution, specifically, sampling distribution proportions samples 50 people. sampling distribution computed tells much estimating true proportion people think work scientists doesn’t benefit . sample proportion unbiased estimator, sampling distribution centered true population proportion, spread distribution indicates much variability incurred sampling 50 people time population. remainder section, work getting sense effect sample size sampling distribution. Use code create sampling distributions proportions Doesn’t benefit samples size 10, 50, 100. Use 5,000 simulations. observation sampling distribution represent? mean, standard error, shape sampling distribution change sample size increases? () values change increase number simulations? (need include plots answer.)","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05a_sampling_distributions.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"05a. Foundations for statistical inference - Sampling distributions","text":"far, focused estimating proportion think work scientists doesn’t benefit . Now, ’ll try estimate proportion think . Note might able answer questions using app, expected write required code produce necessary plots summary statistics. welcome use app exploration. Take sample size 15 population calculate proportion people sample think work scientists enchances lives. Using sample, best point estimate population proportion people think work scientists enchances lives? Since access population, simulate sampling distribution proportion think work scientists enhances lives samples size 15 taking 2000 samples population size 15 computing 2000 sample proportions. Store proportions sample_props15. Plot data, describe shape sampling distribution. Based sampling distribution, guess true proportion think work scientists enhances lives ? Finally, calculate report population proportion. Change sample size 15 150, compute sampling distribution using method , store proportions new object called sample_props150. Describe shape sampling distribution compare sampling distribution sample size 15. Based sampling distribution, guess true proportion think work scientists enhances lives? sampling distributions 2 3, smaller spread? ’re concerned making estimates often close true value, prefer sampling distribution large small spread? work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"05b. Foundations for statistical inference - Confidence intervals","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. Let’s load packages. 2019 Pew Research report states following: keep computation simple, assume total population size 100,000 (even though ’s smaller population size US adults). Roughly six--ten U.S. adults (62%) say climate change currently affecting local community either great deal , according new Pew Research Center survey. Source: Americans say climate change impacts community, effects vary region lab, assume 62% true population proportion learn sample proportions can vary sample sample taking smaller samples population. first create population assuming population size 100,000. means 62,000 (62%) adult population think climate change impacts community, remaining 38,000 think . name data frame us_adults name variable contains responses question “think climate change affecting local community?” climate_change_affects. can quickly visualize distribution responses using bar plot. can also obtain summary statistics confirm constructed data frame correctly. lab, ’ll start simple random sample size 60 population. percent adults sample think climate change affects local community? Hint: Just like population, can calculate proportion sample think climate change affects local community. expect another student’s sample proportion identical ? expect similar? ?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"05b. Foundations for statistical inference - Confidence intervals","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"05b. Foundations for statistical inference - Confidence intervals","text":"2019 Pew Research report states following: keep computation simple, assume total population size 100,000 (even though ’s smaller population size US adults). Roughly six--ten U.S. adults (62%) say climate change currently affecting local community either great deal , according new Pew Research Center survey. Source: Americans say climate change impacts community, effects vary region lab, assume 62% true population proportion learn sample proportions can vary sample sample taking smaller samples population. first create population assuming population size 100,000. means 62,000 (62%) adult population think climate change impacts community, remaining 38,000 think . name data frame us_adults name variable contains responses question “think climate change affecting local community?” climate_change_affects. can quickly visualize distribution responses using bar plot. can also obtain summary statistics confirm constructed data frame correctly. lab, ’ll start simple random sample size 60 population. percent adults sample think climate change affects local community? Hint: Just like population, can calculate proportion sample think climate change affects local community. expect another student’s sample proportion identical ? expect similar? ?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"confidence-intervals","dir":"Articles","previous_headings":"","what":"Confidence intervals","title":"05b. Foundations for statistical inference - Confidence intervals","text":"section, generate bootstrap sample calculate bootstrap proportion group believes climate change affects local community. Return moment question first motivated lab: based sample, can infer population? just one sample, best estimate proportion US adults think climate change affects local community sample proportion, usually denoted p̂\\hat{p} (calling p_hat). serves good point estimate, useful also communicate uncertain estimate. uncertainty can quantified using confidence interval. One way calculating confidence interval population proportion based Central Limit Theorem, p̂±z⋆SEp̂\\hat{p} \\pm z^\\star SE_{\\hat{p}} , precisely, p̂±z⋆p̂(1−p̂)n \\hat{p} \\pm z^\\star \\sqrt{ \\frac{\\hat{p} (1-\\hat{p})}{n} } Another way using simulation, specific, using bootstrapping. term bootstrapping comes phrase “pulling oneself one’s bootstraps”, metaphor accomplishing impossible task without outside help. case impossible task estimating population parameter (unknown population proportion), ’ll accomplish using data given sample. Note notion saying something population parameter using information observed sample crux statistical inference, limited bootstrapping. essence, bootstrapping assumes observations populations like ones observed sample. “reconstruct” population resampling sample, replacement. bootstrapping scheme follows: Step 1. Take bootstrap sample - random sample taken replacement original sample, size original sample. Step 2. Calculate bootstrap statistic - statistic mean, median, proportion, slope, etc. computed bootstrap samples. Step 3. Repeat steps (1) (2) many times create bootstrap distribution - distribution bootstrap statistics. Step 4. Calculate bounds XX% confidence interval middle XX% bootstrap distribution. Instead coding steps, construct confidence intervals using infer package. overview functions use construct confidence interval: code find 95 percent confidence interval proportion US adults think climate change affects local community. specify specify response variable level variable calling success. generate provide number resamples want population reps argument (reasonably large number) well type resampling want , \"bootstrap\" case constructing confidence interval. , calculate sample statistic interest resamples, proportion. Feel free test rest arguments functions, since commands used together calculate confidence intervals solve inference problems rest semester. also walk examples future chapters. recap: even though don’t know full population looks like, ’re 95% confident true proportion US adults think climate change affects local community two bounds reported result pipeline.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"confidence-levels","dir":"Articles","previous_headings":"","what":"Confidence levels","title":"05b. Foundations for statistical inference - Confidence intervals","text":"interpretation , used phrase “95% confident”. “95% confidence” mean? case, rare luxury knowing true population proportion (62%) since data entire population. confidence interval capture true population proportion US adults think climate change affects local community? working lab classroom, neighbor’s interval capture value? student gotten slightly different confidence interval. proportion intervals expect capture true population mean? ? next part lab, collect many samples learn sample proportions confidence intervals constructed based samples vary one sample another. Obtain random sample. Calculate sample proportion, use calculate store lower upper bounds confidence intervals. Repeat steps 50 times. require learning programming concepts like iteration can automate repeating running code ’ve developed far many times obtain many (50) confidence intervals. order keep programming simpler, providing interactive app basically created plot similar Figure 5.6 OpenIntro Statistics, 4th Edition (page 182). Given sample size 60, 1000 bootstrap samples interval, 50 confidence intervals constructed (default values app), proportion confidence intervals include true population proportion? proportion exactly equal confidence level? , explain . Make sure include plot answer.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/05b_confidence_intervals.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"05b. Foundations for statistical inference - Confidence intervals","text":"Choose different confidence level 95% (changing conf_level <- 0.95) expect confidence interval level wider narrower confidence interval calculated 95% confidence level? Explain reasoning. Using code infer package data one sample (samp), find confidence interval proportion US Adults think climate change affecting local community confidence level choosing (95%) interpret . Calculate 50 confidence intervals confidence level chose previous question, plot intervals one plot, calculate proportion intervals include true population proportion. percentage compare confidence level selected intervals? Lastly, try one (different) confidence level. First, state expect width interval compare previous ones calculated. , calculate bounds interval using infer package data samp interpret . Finally, generate many intervals calculate proportion intervals capture true population proportion. Experiment different sample sizes (n_samp) comment widths intervals change sample size changes (increases decreases). Finally, given sample size (say, 60), width interval change increase number bootstrap samples (n_rep). Hint: changing number bootstrap samples affect standard error? work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"06. Inference for categorical Data","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. data can found companion package OpenIntro resources, openintro. Let’s load packages. analyzing dataset previous lab, delved sample Youth Risk Behavior Surveillance System (YRBSS) survey, uses data high schoolers help discover health patterns. dataset called yrbss. counts within category amount days students texted driving within past 30 days? proportion people texted driving every day past 30 days never wear helmets? Remember can use filter limit dataset just non-helmet wearers. , name dataset no_helmet. Also, may easier calculate proportion create new variable specifies whether individual texted every day driving past 30 days . call variable text_ind.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"06. Inference for categorical Data","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. data can found companion package OpenIntro resources, openintro. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"06. Inference for categorical Data","text":"analyzing dataset previous lab, delved sample Youth Risk Behavior Surveillance System (YRBSS) survey, uses data high schoolers help discover health patterns. dataset called yrbss. counts within category amount days students texted driving within past 30 days? proportion people texted driving every day past 30 days never wear helmets? Remember can use filter limit dataset just non-helmet wearers. , name dataset no_helmet. Also, may easier calculate proportion create new variable specifies whether individual texted every day driving past 30 days . call variable text_ind.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"inference-on-proportions","dir":"Articles","previous_headings":"","what":"Inference on proportions","title":"06. Inference for categorical Data","text":"summarizing YRBSS, Centers Disease Control Prevention seeks insight population parameters. , can answer question, “proportion people sample reported texted driving day past 30 days?” statistic; question “proportion people earth texted driving day past 30 days?” answered estimate parameter. inferential tools estimating population proportion analogous used means last chapter: confidence interval hypothesis test. Note since goal construct interval estimate proportion, ’s necessary include success argument within specify, accounts proportion non-helmet wearers consistently texted driving past 30 days, example, stat within calculate “prop”, signaling trying sort inference proportion. margin error estimate proportion non-helmet wearers texted driving day past 30 days based survey? Using infer package, calculate confidence intervals two categorical variables (’ll need decide level call “success”, report associated margins error. Interpret interval context data. may helpful create new data sets two countries first, use data sets construct confidence intervals.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"how-does-the-proportion-affect-the-margin-of-error","dir":"Articles","previous_headings":"","what":"How does the proportion affect the margin of error?","title":"06. Inference for categorical Data","text":"Imagine ’ve set survey 1000 people two questions: least 6-feet tall? left-handed? Since sample proportions calculated sample size, margin error, right? Wrong! margin error change sample size, also affected proportion. Think back formula standard error: SE=p(1−p)/nSE = \\sqrt{p(1-p)/n}. used formula margin error 95% confidence interval: =1.96×SE=1.96×p(1−p)/n. = 1.96\\times SE = 1.96\\times\\sqrt{p(1-p)/n} \\,.  Since population proportion pp MEME formula, make sense margin error way dependent population proportion. can visualize relationship creating plot MEME vs. pp. Since sample size irrelevant discussion, let’s just set value (n=1000n = 1000) use value following calculations: first step make variable p sequence 0 1 number incremented 0.01. can create variable margin error () associated values p using familiar approximate formula (=2×SEME = 2 \\times SE). Lastly, can plot two variables reveal relationship. , need first put variables data frame can call ggplot function. Describe relationship p . Include margin error vs. population proportion plot constructed answer. given sample size, value p margin error maximized?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"success-failure-condition","dir":"Articles","previous_headings":"","what":"Success-failure condition","title":"06. Inference for categorical Data","text":"emphasized must always check conditions making inference. inference proportions, sample proportion can assumed nearly normal based upon random sample independent observations np≥10np \\geq 10 n(1−p)≥10n(1 - p) \\geq 10. rule thumb easy enough follow, makes wonder: ’s special number 10? short answer : nothing. argue fine 9 really using 11. “best” value rule thumb , least degree, arbitrary. However, npnp n(1−p)n(1-p) reaches 10 sampling distribution sufficiently normal use confidence intervals hypothesis tests based approximation. can investigate interplay nn pp shape sampling distribution using simulations. Play around parameters investigate shape, center, spread distribution p̂\\hat{p} changes nn pp change. Describe sampling distribution sample proportions n=300n = 300 p=0.1p = 0.1. sure note center, spread, shape. Keep nn constant change pp. shape, center, spread sampling distribution vary pp changes. might want adjust min max xx-axis better view distribution. Now also change nn. nn appear affect distribution p̂\\hat{p}?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/06_inf_for_categorical_data.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"06. Inference for categorical Data","text":"exercises , conduct inference comparing two proportions. cases, response variable categorical, explanatory variable also categorical, comparing proportions success response variable across levels explanatory variable. means using infer, need include variables within specify. convincing evidence sleep 10+ hours per day likely strength train every day week? always, write hypotheses tests conduct outline status conditions inference. find significant difference, also quantify difference confidence interval. Let’s say difference likeliness strength train every day week sleep 10+ hours. probability detect change (significance level 0.05) simply chance? Hint: Review definition Type 1 error. Suppose ’re hired local government estimate proportion residents attend religious service weekly basis. According guidelines, estimate must margin error greater 1% 95% confidence. idea expect pp. many people sample ensure within guidelines?Hint: Refer plot relationship pp margin error. question require using dataset. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"07. Inference for numerical data","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. data can found companion package OpenIntro resources, openintro. Let’s load packages. Every two years, Centers Disease Control Prevention conduct Youth Risk Behavior Surveillance System (YRBSS) survey, takes data high schoolers (9th 12th grade), analyze health patterns. work selected group variables random sample observations one years YRBSS conducted. Load yrbss data set workspace. observations 13 different variables, categorical numerical. meaning variable can found bringing help file: cases data set? many cases sample? Remember can answer question viewing data data viewer using glimpse(yrbss).","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"07. Inference for numerical data","text":"lab, explore visualize data using tidyverse suite packages, perform statistical inference using infer. data can found companion package OpenIntro resources, openintro. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"07. Inference for numerical data","text":"Every two years, Centers Disease Control Prevention conduct Youth Risk Behavior Surveillance System (YRBSS) survey, takes data high schoolers (9th 12th grade), analyze health patterns. work selected group variables random sample observations one years YRBSS conducted. Load yrbss data set workspace. observations 13 different variables, categorical numerical. meaning variable can found bringing help file: cases data set? many cases sample? Remember can answer question viewing data data viewer using glimpse(yrbss).","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"exploratory-data-analysis","dir":"Articles","previous_headings":"","what":"Exploratory data analysis","title":"07. Inference for numerical data","text":"first start analyzing weight participants kilograms: weight. Using visualization summary statistics, describe distribution weights. skim() function skimr package produces nice summaries variables dataset, separating categorical (character) variables quantitative variables. many observations missing weights ? Next, consider possible relationship high schooler’s weight physical activity. Plotting data useful first step helps us quickly visualize trends, identify strong associations, develop research questions. First, let’s create new variable physical_3plus, coded either “yes” student physically active least 3 days week, “” . Make side--side violin plots physical_3plus weight. relationship two variables? expect ? box plots show medians two distributions compare, can also compare means distributions using following first group data physical_3plus variable, calculate mean weight groups using mean function ignoring missing values setting na.rm argument TRUE. observed difference, difference large enough deem “statistically significant”? order answer question conduct hypothesis test.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"inference","dir":"Articles","previous_headings":"","what":"Inference","title":"07. Inference for numerical data","text":"conditions necessary inference satisfied? Comment . can compute group sizes summarize command defining new variable definition n(). Write hypotheses testing average weights different exercise least times week don’t. Next, work creating permutation distribution using tools infer package. first, need initialize test, save obs_diff. Recall specify() function used specify variables considering (notated y ~ x), can use calculate() function specify statistic want calculate order subtraction want use. hypothesis, statistic searching difference means, order yes - . calculated observed statistic, need create permutation distribution. distribution created shuffling observed weights new physical_3plus groups, labeled “yes” “”. save permutation distribution null_dist. hypothesize() function used declare null hypothesis . , assuming student’s weight independent whether exercise least 3 days . also note type argument within generate() set \"permute\". ensures statistics calculated calculate() function come reshuffling data (resampling data)! Finally, specify() calculate() steps look familiar, since used find observed difference means! can visualize null distribution following code: Add vertical red line plot , demonstrating observed difference means (obs_diff) falls distribution. many null_dist permutations difference least large (larger) obs_diff? Now calculated observed statistic generated permutation distribution, can calculate p-value hypothesis test using function get_p_value() infer package. warning message get? think get warning message? Construct record confidence interval difference weights exercise least three times week don’t, interpret interval context data.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/07_inf_for_numerical_data.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"07. Inference for numerical data","text":"Calculate 95% confidence interval average height meters (height) interpret context. Calculate new confidence interval parameter 90% confidence level. Comment width interval versus one obtained previous exercise. Conduct hypothesis test evaluating whether average height different exercise least three times week don’t. Now, non-inference task: Determine number different options dataset hours_tv_per_school_day . Come research question evaluating relationship height weight sleep. Formulate question way can answered using hypothesis test /confidence interval. Report statistical results, also provide explanation plain language. sure check assumptions, state α\\alpha level, conclude context. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"08. Introduction to linear regression","text":"lab, explore visualize data using tidyverse suite packages. also use statsr package select regression line minimizes sum squared residuals broom package tidy regression output. data can found openintro package, companion package OpenIntro resources. Let’s load packages. data ’re working openintro package ’s called hfi, short Human Freedom Index. dimensions dataset? row represent? dataset spans lot years, interested data year 2016. Filter data hfi data frame year 2016, select six variables, assign result data frame named hfi_2016. type plot use display relationship personal freedom score, pf_score, pf_expression_control? Plot relationship using variable pf_expression_control predictor. relationship look linear? knew country’s pf_expression_control, score 10, 0 , political pressures controls media content, comfortable using linear model predict personal freedom score? relationship looks linear, can quantify strength relationship correlation coefficient.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"08. Introduction to linear regression","text":"lab, explore visualize data using tidyverse suite packages. also use statsr package select regression line minimizes sum squared residuals broom package tidy regression output. data can found openintro package, companion package OpenIntro resources. Let’s load packages.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"08. Introduction to linear regression","text":"data ’re working openintro package ’s called hfi, short Human Freedom Index. dimensions dataset? row represent? dataset spans lot years, interested data year 2016. Filter data hfi data frame year 2016, select six variables, assign result data frame named hfi_2016. type plot use display relationship personal freedom score, pf_score, pf_expression_control? Plot relationship using variable pf_expression_control predictor. relationship look linear? knew country’s pf_expression_control, score 10, 0 , political pressures controls media content, comfortable using linear model predict personal freedom score? relationship looks linear, can quantify strength relationship correlation coefficient.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"sum-of-squared-residuals","dir":"Articles","previous_headings":"","what":"Sum of squared residuals","title":"08. Introduction to linear regression","text":"section, use interactive function investigate mean “sum squared residuals”. need run function console, markdown document. Running function also requires hfi dataset loaded environment. also need make sure Plots tab lower right-hand corner enough space make plot. Think back way described distribution single variable. Recall discussed characteristics center, spread, shape. ’s also useful able describe relationship two numerical variables, pf_expression_control pf_score . Looking plot previous exercise, describe relationship two variables. Make sure discuss form, direction, strength relationship well unusual observations. Just ’ve used mean standard deviation summarize single variable, can summarize relationship two variables finding line best follows association. Use following interactive function select line think best job going cloud points. running command, ’ll prompted click two points plot define line. ’ve done , line specified shown black residuals blue. plot appearing code chunk won’t let select points make line, take following steps: Go Tools bar top RStudio Click “Global Options…” Click “R Markdown pane” (left) Uncheck box says “Show output inline R Markdown documents” Recall residuals difference observed values values predicted line: ei=yi−ŷ  e_i = y_i - \\hat{y}_i common way linear regression select line minimizes sum squared residuals. visualize squared residuals, can rerun plot command add argument showSquares = TRUE. Note output plot_ss function provides slope intercept line well sum squares. Using plot_ss, choose line good job minimizing sum squares. Run function several times. smallest sum squares got? compare neighbours?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"the-linear-model","dir":"Articles","previous_headings":"","what":"The linear model","title":"08. Introduction to linear regression","text":"rather cumbersome try get correct least squares line, .e. line minimizes sum squared residuals, trial error. Instead, can use lm function R fit linear model (.k.. regression line). first argument function lm() formula takes form y ~ x. can read want make linear model pf_score function pf_expression_control. second argument specifies R look hfi data frame find two variables. Note: Piping work , data frame first argument! output lm() object contains information need linear model just fit. can access information using tidy() function. Let’s consider output piece piece. First, formula used describe model shown top, ’s displayed “Call”. formula find five-number summary residuals. “Coefficients” table shown next key; first column displays linear model’s y-intercept coefficient pf_expression_control. table, can write least squares regression line linear model: ŷ=4.28+0.542×pf_expression_control   \\hat{y} = 4.28 + 0.542 \\times pf\\_expression\\_control equation tells us two things: countries pf_expression_control 0 (largest amount political pressure media content), expect mean personal freedom score 4.28. every 1 unit increase pf_expression_control, expect country’s mean personal freedom score increase 0.542 units. can assess model fit using R2R^2, proportion variability response variable explained explanatory variable. use glance() function access information. model, 71.4% variability pf_score explained pf_expression_control. Fit new model uses pf_expression_control predict hf_score, total human freedom score. Using estimates R output, write equation regression line. slope tell us context relationship human freedom amount political pressure media content?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"prediction-and-prediction-errors","dir":"Articles","previous_headings":"","what":"Prediction and prediction errors","title":"08. Introduction to linear regression","text":"Let’s create scatterplot least squares line m1 laid top. , literally adding layer top plot. geom_smooth creates line fitting linear model. can also show us standard error se associated line, ’ll suppress now. line can used predict yy value xx. predictions made values xx beyond range observed data, referred extrapolation usually recommended. However, predictions made within range data reliable. ’re also used compute residuals. someone saw least squares regression line actual data, predict country’s personal freedom school one 3 rating pf_expression_control? overestimate underestimate, much? words, residual prediction?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"model-diagnostics","dir":"Articles","previous_headings":"","what":"Model diagnostics","title":"08. Introduction to linear regression","text":"assess whether linear model reliable, need check (1) linearity, (2) nearly normal residuals, (3) constant variability. order checks need access fitted (predicted) values residuals. can use augment() function calculate . Linearity: already checked relationship pf_score pf_expression_control linear using scatterplot. also verify condition plot residuals vs. fitted (predicted) values. Notice m1 can also serve data set stored within fitted values (ŷ\\hat{y}) residuals. Also note ’re getting fancy code . creating scatterplot first layer (first line code), overlay red horizontal dashed line y=0y = 0 (help us check whether residuals distributed around 0), also rename axis labels informative. apparent pattern residuals plot? indicate linearity relationship two variables?  Nearly normal residuals: check condition, can look histogram residuals. Based histogram, nearly normal residuals condition appear violated? ?  Constant variability: Based residuals vs. fitted plot, constant variability condition appear violated? ?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/08_simple_regression.html","id":"more-practice","dir":"Articles","previous_headings":"","what":"More Practice","title":"08. Introduction to linear regression","text":"Choose another variable think strongly correlate pf_score. Produce scatterplot two variables fit linear model. glance, seem linear relationship? relationship compare relationship pf_score pf_expression_control? Use R2R^2 values two model summaries compare. independent variable seem predict pf_score better? ? Check model diagnostics using appropriate visualizations evaluate model conditions met. Pick another pair variables interest visualize relationship . find relationship surprising expected. Discuss interested variables /surprised relationship observed. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"grading-the-professor","dir":"Articles","previous_headings":"","what":"Grading the professor","title":"09. Multiple regression","text":"Many college courses conclude giving students opportunity evaluate course instructor anonymously. However, use student evaluations indicator course quality teaching effectiveness often criticized measures may reflect influence non-teaching related characteristics, physical appearance instructor. article titled, “Beauty classroom: instructors’ pulchritude putative pedagogical productivity” Hamermesh Parker found instructors viewed better looking receive higher instructional ratings. , analyze data study order learn goes positive professor evaluation.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting Started","title":"09. Multiple regression","text":"lab, explore visualize data using tidyverse suite packages. also use GGally package visualisation many variables broom package tidy regression output. data can found companion package OpenIntro resources, openintro. Let’s load packages. first time ’re using GGally package. using ggpairs() function package later lab. data gathered end semester student evaluations large sample professors University Texas Austin. addition, six students rated professors’ physical appearance. result data frame row contains different course columns represent variables courses professors. ’s called evals. observations 21 different variables, categorical numerical. meaning variable can found bringing help file:","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"load-packages","dir":"Articles","previous_headings":"","what":"Load packages","title":"09. Multiple regression","text":"lab, explore visualize data using tidyverse suite packages. also use GGally package visualisation many variables broom package tidy regression output. data can found companion package OpenIntro resources, openintro. Let’s load packages. first time ’re using GGally package. using ggpairs() function package later lab.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"09. Multiple regression","text":"data gathered end semester student evaluations large sample professors University Texas Austin. addition, six students rated professors’ physical appearance. result data frame row contains different course columns represent variables courses professors. ’s called evals. observations 21 different variables, categorical numerical. meaning variable can found bringing help file:","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"exploring-the-data","dir":"Articles","previous_headings":"","what":"Exploring the data","title":"09. Multiple regression","text":"observational study experiment? original research question posed paper whether beauty leads directly differences course evaluations. Given study design, possible answer question phrased? , rephrase question. Describe distribution score. distribution skewed? tell students rate courses? expected see? , ? Excluding score, select two variables describe relationship using appropriate visualization.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"simple-linear-regression","dir":"Articles","previous_headings":"","what":"Simple linear regression","title":"09. Multiple regression","text":"fundamental phenomenon suggested study better looking teachers evaluated favourably. Let’s create scatterplot see appears case: draw conclusions trend, compare number observations data frame approximate number points scatterplot. anything awry? Re-plot scatterplot, time use geom_jitter layer. misleading initial scatterplot? Let’s see apparent trend plot something natural variation. Fit linear model called m_bty predict average professor score average beauty rating. Write equation linear model interpret slope. average beauty score statistically significant predictor? appear practically significant predictor? Add line bet fit model plot using following: blue line model. shaded gray area around line tells variability might expect predictions. turn , use se = FALSE. Use residual plots evaluate whether conditions least squares regression reasonable. Provide plots comments one (see Simple Regression Lab reminder make ).","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"multiple-linear-regression","dir":"Articles","previous_headings":"","what":"Multiple linear regression","title":"09. Multiple regression","text":"data set contains several variables beauty score professor: individual ratings six students asked score physical appearance professors average six scores. Let’s take look relationship one scores average beauty score. expected, relationship quite strong—, average score calculated using individual scores. can actually look relationships beauty variables (columns 13 19) using following command: variables collinear (correlated), adding one variables model add much value model. application highly-correlated predictors, reasonable use average beauty score single representative variables. order see beauty still significant predictor professor score ’ve accounted professor’s gender, can add gender term model. p-values parameter estimates trusted conditions regression reasonable. Verify conditions model reasonable using diagnostic plots. bty_avg still significant predictor score? addition gender model changed parameter estimate bty_avg? Note estimate gender now called gendermale. ’ll see name change whenever introduce categorical variable. reason R recodes gender values male female indicator variable called gendermale takes value 00 female professors value 11 male professors. (variables often referred “dummy” variables.) result, female professors, parameter estimate multiplied zero, leaving intercept slope form familiar simple regression. scorê=β̂0+β̂1×bty_avg+β̂2×(0)=β̂0+β̂1×bty_avg   \\begin{aligned} \\widehat{score} &= \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times bty\\_avg + \\hat{\\beta}_2 \\times (0) \\\\ &= \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times bty\\_avg\\end{aligned} equation line corresponding male professors? (Hint: male professors, parameter estimate multiplied 1.) two professors received beauty rating, gender tends higher course evaluation score? decision call indicator variable gendermale instead genderfemale deeper meaning. R simply codes category comes first alphabetically 00. (can change reference level categorical variable, level coded 0, using therelevel() function. Use ?relevel learn .) Create new model called m_bty_rank gender removed rank added . R appear handle categorical variables two levels? Note rank variable three levels: teaching, tenure track, tenured. interpretation coefficients multiple regression slightly different simple regression. estimate bty_avg reflects much higher group professors expected score beauty rating one point higher holding variables constant. case, translates considering professors rank bty_avg scores one point apart.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"the-search-for-the-best-model","dir":"Articles","previous_headings":"","what":"The search for the best model","title":"09. Multiple regression","text":"start full model predicts professor score based rank, gender, ethnicity, language university got degree, age, proportion students filled evaluations, class size, course level, number professors, number credits, average beauty rating. variable expect highest p-value model? ? Hint: Think variable expect association professor score. Let’s run model… Check suspicions previous exercise. Include model output response. Interpret coefficient associated ethnicity variable. Drop one variable time peek adjusted R2R^2. Removing variable increases adjusted R2R^2 ? Drop variable highest p-value re-fit model. coefficients significance explanatory variables change variable removed? (One things makes multiple regression interesting coefficient estimates depend variables included model.) , say whether dropped variable collinear explanatory variables? Using backward-selection adjusted R2R^2 selection criterion, determine best model. need show steps answer, just output final model. Also, write linear model predicting score based final model settle . Verify conditions model reasonable using diagnostic plots. original paper describes data gathered taking sample professors University Texas Austin including courses taught. Considering row represents course, new information impact conditions linear regression? Based final model, describe characteristics professor course University Texas Austin associated high evaluation score. comfortable generalizing conclusions apply professors generally (university)? ?","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/09_multiple_regression.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"09. Multiple regression","text":"work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/MyAssignment.html","id":"the-data","dir":"Articles","previous_headings":"","what":"The data","title":"My Assignment","text":"data ’re working openintro package ’s called hfi, short Human Freedom Index. dimensions dataset? row represent?","code":"dim(hfi) ## [1] 1458  123 head(hfi) ## # A tibble: 6 × 123 ##    year ISO_code countries region pf_rol_procedural pf_rol_civil pf_rol_criminal ##   <dbl> <chr>    <chr>     <chr>              <dbl>        <dbl>           <dbl> ## 1  2016 ALB      Albania   Easte…              6.66         4.55            4.67 ## 2  2016 DZA      Algeria   Middl…             NA           NA              NA    ## 3  2016 AGO      Angola    Sub-S…             NA           NA              NA    ## 4  2016 ARG      Argentina Latin…              7.10         5.79            4.34 ## 5  2016 ARM      Armenia   Cauca…             NA           NA              NA    ## 6  2016 AUS      Australia Ocean…              8.44         7.53            7.36 ## # ℹ 116 more variables: pf_rol <dbl>, pf_ss_homicide <dbl>, ## #   pf_ss_disappearances_disap <dbl>, pf_ss_disappearances_violent <dbl>, ## #   pf_ss_disappearances_organized <dbl>, ## #   pf_ss_disappearances_fatalities <dbl>, pf_ss_disappearances_injuries <dbl>, ## #   pf_ss_disappearances <dbl>, pf_ss_women_fgm <dbl>, ## #   pf_ss_women_missing <dbl>, pf_ss_women_inheritance_widows <dbl>, ## #   pf_ss_women_inheritance_daughters <dbl>, pf_ss_women_inheritance <dbl>, … hfi_2016 <- hfi %>%    filter(year == 2016) library(ggplot2)  ggplot(hfi_2016, aes(x = pf_expression_control, y = pf_score)) +   geom_point() +   labs(title = \"Relationship between Personal Freedom Score and Expression Control\",        x = \"Expression Control\",        y = \"Personal Freedom Score\") +   theme_minimal() library(ggplot2)  # Fit the linear model model <- lm(pf_score ~ pf_expression_control, data = hfi_2016)  # Create a new data frame for predictions new_data <- data.frame(pf_expression_control = hfi_2016$pf_expression_control)  # Get predictions with confidence and prediction intervals predictions <- predict(model, newdata = new_data, interval = \"prediction\", level = 0.95)  # Combine the predictions with the original data hfi_2016 <- cbind(hfi_2016, predictions)  # Plot with ggplot2 ggplot(hfi_2016, aes(x = pf_expression_control, y = pf_score)) +   geom_point() +   geom_smooth(method = \"lm\", se = TRUE) +   geom_line(aes(y = lwr), color = \"blue\", linetype = \"dashed\") +   geom_line(aes(y = upr), color = \"blue\", linetype = \"dashed\") +   labs(title = \"Relationship between Personal Freedom Score and Expression Control\",        x = \"Expression Control\",        y = \"Personal Freedom Score\") +   theme_minimal() ## `geom_smooth()` using formula = 'y ~ x'"},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"codebook-arbuthnot-london-births-dataset","dir":"Articles","previous_headings":"","what":"Codebook: Arbuthnot London Births Dataset","title":"Codebook for arbuthnot dataset","text":"Dataset name: arbuthnot Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually dataset contains historical records births London 1629 1710, recorded John Arbuthnot. dataset includes 82 observations 4 variables, documenting number boys girls christened year. Description: Calendar year birth records Type: Numeric (integer) Range: 1629 1710 Missing values: None Description: Number male children christened London Type: Numeric (integer) Range: 2,890 8,426 Missing values: None Description: Number female children christened London Type: Numeric (integer) Range: 2,722 7,779 Missing values: None Start year: 1629 End year: 1710 Total years: 82 Total boys christened: 484,382 Total girls christened: 453,841 Overall boy/girl ratio: 1.067 Average boys per year: 5,907 Average girls per year: 5,535 Minimum total births (1650): 5,612 Maximum total births (1705): 16,145 dataset complete missing values counts positive integers Consistent annual records entire period Data represents christenings rather births, actual birth numbers may higher dataset compiled John Arbuthnot (1667-1735), Scottish physician, mathematician, satirist. used records study ratio male female births, making one earliest known applications statistical reasoning scientific question. original data comes London Bills Mortality, recorded christenings, burials, causes death London parishes 16th 19th centuries. codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"where-to-find-it","dir":"Articles","previous_headings":"","what":"Where to find it","title":"Codebook for arbuthnot dataset","text":"Dataset name: arbuthnot Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for arbuthnot dataset","text":"dataset contains historical records births London 1629 1710, recorded John Arbuthnot. dataset includes 82 observations 4 variables, documenting number boys girls christened year.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for arbuthnot dataset","text":"Description: Calendar year birth records Type: Numeric (integer) Range: 1629 1710 Missing values: None Description: Number male children christened London Type: Numeric (integer) Range: 2,890 8,426 Missing values: None Description: Number female children christened London Type: Numeric (integer) Range: 2,722 7,779 Missing values: None Start year: 1629 End year: 1710 Total years: 82 Total boys christened: 484,382 Total girls christened: 453,841 Overall boy/girl ratio: 1.067 Average boys per year: 5,907 Average girls per year: 5,535 Minimum total births (1650): 5,612 Maximum total births (1705): 16,145","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"year","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"year","title":"Codebook for arbuthnot dataset","text":"Description: Calendar year birth records Type: Numeric (integer) Range: 1629 1710 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"boys","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"boys","title":"Codebook for arbuthnot dataset","text":"Description: Number male children christened London Type: Numeric (integer) Range: 2,890 8,426 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"girls","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"girls","title":"Codebook for arbuthnot dataset","text":"Description: Number female children christened London Type: Numeric (integer) Range: 2,722 7,779 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"time-period-coverage","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"Time Period Coverage","title":"Codebook for arbuthnot dataset","text":"Start year: 1629 End year: 1710 Total years: 82","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"birth-totals","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"Birth Totals","title":"Codebook for arbuthnot dataset","text":"Total boys christened: 484,382 Total girls christened: 453,841 Overall boy/girl ratio: 1.067","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"annual-averages","dir":"Articles","previous_headings":"Codebook: Arbuthnot London Births Dataset","what":"Annual Averages","title":"Codebook for arbuthnot dataset","text":"Average boys per year: 5,907 Average girls per year: 5,535 Minimum total births (1650): 5,612 Maximum total births (1705): 16,145","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for arbuthnot dataset","text":"dataset complete missing values counts positive integers Consistent annual records entire period Data represents christenings rather births, actual birth numbers may higher","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"historical-context","dir":"Articles","previous_headings":"","what":"Historical Context","title":"Codebook for arbuthnot dataset","text":"dataset compiled John Arbuthnot (1667-1735), Scottish physician, mathematician, satirist. used records study ratio male female births, making one earliest known applications statistical reasoning scientific question.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"source","dir":"Articles","previous_headings":"","what":"Source","title":"Codebook for arbuthnot dataset","text":"original data comes London Bills Mortality, recorded christenings, burials, causes death London parishes 16th 19th centuries.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_arbuthnot.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for arbuthnot dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"codebook-fast-food-nutrition-dataset","dir":"Articles","previous_headings":"","what":"Codebook: Fast Food Nutrition Dataset","title":"Codebook for fastfood dataset","text":"Dataset name: fastfood Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually dataset contains nutritional information various fast food items different restaurants. dataset includes multiple observations 17 variables. Description: Name restaurant Type: Categorical Values: Various restaurant names (e.g., Mcdonalds, Chick Fil-, Sonic, etc.) Missing values: None Description: Name food item Type: Categorical Values: Various food item names (e.g., Big Mac, Chicken Sandwich, etc.) Missing values: None Note: value unique Description: Total calories food item Type: Numeric Values: Range 20 2430 Missing values: None Description: Calories fat Type: Numeric Values: Range 0 1270 Missing values: None Description: Total fat content grams Type: Numeric Values: Range 0 141 Missing values: None Description: Saturated fat content grams Type: Numeric Values: Range 0 47 Missing values: None Description: Trans fat content grams Type: Numeric Values: Range 0 8 Missing values: None Description: Cholesterol content milligrams Type: Numeric Values: Range 0 805 Missing values: None Description: Sodium content milligrams Type: Numeric Values: Range 0 6080 Missing values: None Description: Total carbohydrate content grams Type: Numeric Values: Range 0 156 Missing values: none Description: Dietary fiber content grams Type: Numeric Values: Range 0 17 Missing values: 12 Description: Sugar content grams Type: Numeric Values: Range 0 87 Missing values: None Description: Protein content grams Type: Numeric Values: Range 0 186 Missing values: 1 Description: Vitamin content percentage daily value Type: Numeric Values: Range 0 180 Missing values: 214 Description: Vitamin C content percentage daily value Type: Numeric Values: Range 0 400 Missing values: 210 Description: Calcium content percentage daily value Type: Numeric Values: Range 0 290 Missing values: 210 Description: Indicates item salad Type: Categorical Values: - = salad Missing values: None item omitted brevity since value unique. dataset 301 complete cases 214 observations missing values. variables coded consistently. Nutritional values provided standard units (grams, milligrams, percentages). codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"where-to-find-it","dir":"Articles","previous_headings":"","what":"Where to find it","title":"Codebook for fastfood dataset","text":"Dataset name: fastfood Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for fastfood dataset","text":"dataset contains nutritional information various fast food items different restaurants. dataset includes multiple observations 17 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for fastfood dataset","text":"Description: Name restaurant Type: Categorical Values: Various restaurant names (e.g., Mcdonalds, Chick Fil-, Sonic, etc.) Missing values: None Description: Name food item Type: Categorical Values: Various food item names (e.g., Big Mac, Chicken Sandwich, etc.) Missing values: None Note: value unique Description: Total calories food item Type: Numeric Values: Range 20 2430 Missing values: None Description: Calories fat Type: Numeric Values: Range 0 1270 Missing values: None Description: Total fat content grams Type: Numeric Values: Range 0 141 Missing values: None Description: Saturated fat content grams Type: Numeric Values: Range 0 47 Missing values: None Description: Trans fat content grams Type: Numeric Values: Range 0 8 Missing values: None Description: Cholesterol content milligrams Type: Numeric Values: Range 0 805 Missing values: None Description: Sodium content milligrams Type: Numeric Values: Range 0 6080 Missing values: None Description: Total carbohydrate content grams Type: Numeric Values: Range 0 156 Missing values: none Description: Dietary fiber content grams Type: Numeric Values: Range 0 17 Missing values: 12 Description: Sugar content grams Type: Numeric Values: Range 0 87 Missing values: None Description: Protein content grams Type: Numeric Values: Range 0 186 Missing values: 1 Description: Vitamin content percentage daily value Type: Numeric Values: Range 0 180 Missing values: 214 Description: Vitamin C content percentage daily value Type: Numeric Values: Range 0 400 Missing values: 210 Description: Calcium content percentage daily value Type: Numeric Values: Range 0 290 Missing values: 210 Description: Indicates item salad Type: Categorical Values: - = salad Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"restaurant","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"restaurant","title":"Codebook for fastfood dataset","text":"Description: Name restaurant Type: Categorical Values: Various restaurant names (e.g., Mcdonalds, Chick Fil-, Sonic, etc.) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"item","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"item","title":"Codebook for fastfood dataset","text":"Description: Name food item Type: Categorical Values: Various food item names (e.g., Big Mac, Chicken Sandwich, etc.) Missing values: None Note: value unique","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"calories","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"calories","title":"Codebook for fastfood dataset","text":"Description: Total calories food item Type: Numeric Values: Range 20 2430 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"cal_fat","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"cal_fat","title":"Codebook for fastfood dataset","text":"Description: Calories fat Type: Numeric Values: Range 0 1270 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"total_fat","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"total_fat","title":"Codebook for fastfood dataset","text":"Description: Total fat content grams Type: Numeric Values: Range 0 141 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"sat_fat","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"sat_fat","title":"Codebook for fastfood dataset","text":"Description: Saturated fat content grams Type: Numeric Values: Range 0 47 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"trans_fat","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"trans_fat","title":"Codebook for fastfood dataset","text":"Description: Trans fat content grams Type: Numeric Values: Range 0 8 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"cholesterol","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"cholesterol","title":"Codebook for fastfood dataset","text":"Description: Cholesterol content milligrams Type: Numeric Values: Range 0 805 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"sodium","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"sodium","title":"Codebook for fastfood dataset","text":"Description: Sodium content milligrams Type: Numeric Values: Range 0 6080 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"total_carb","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"total_carb","title":"Codebook for fastfood dataset","text":"Description: Total carbohydrate content grams Type: Numeric Values: Range 0 156 Missing values: none","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"fiber","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"fiber","title":"Codebook for fastfood dataset","text":"Description: Dietary fiber content grams Type: Numeric Values: Range 0 17 Missing values: 12","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"sugar","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"sugar","title":"Codebook for fastfood dataset","text":"Description: Sugar content grams Type: Numeric Values: Range 0 87 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"protein","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"protein","title":"Codebook for fastfood dataset","text":"Description: Protein content grams Type: Numeric Values: Range 0 186 Missing values: 1","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"vit_a","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"vit_a","title":"Codebook for fastfood dataset","text":"Description: Vitamin content percentage daily value Type: Numeric Values: Range 0 180 Missing values: 214","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"vit_c","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"vit_c","title":"Codebook for fastfood dataset","text":"Description: Vitamin C content percentage daily value Type: Numeric Values: Range 0 400 Missing values: 210","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"calcium","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"calcium","title":"Codebook for fastfood dataset","text":"Description: Calcium content percentage daily value Type: Numeric Values: Range 0 290 Missing values: 210","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"salad","dir":"Articles","previous_headings":"Codebook: Fast Food Nutrition Dataset","what":"salad","title":"Codebook for fastfood dataset","text":"Description: Indicates item salad Type: Categorical Values: - = salad Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook for fastfood dataset","text":"item omitted brevity since value unique.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for fastfood dataset","text":"dataset 301 complete cases 214 observations missing values. variables coded consistently. Nutritional values provided standard units (grams, milligrams, percentages).","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_fastfood.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for fastfood dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"codebook-kobe-bryant-basketball-dataset","dir":"Articles","previous_headings":"","what":"Codebook: Kobe Bryant Basketball Dataset","title":"Codebook for kobe_basket dataset","text":"Dataset name: kobe_basket Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually dataset contains information Kobe Bryant’s basketball shots, including opponent, game details, shot description, whether shot made missed. dataset includes multiple observations 6 variables. Description: Opponent team Type: Categorical Values: Various team abbreviations (e.g., ORL, MIA, etc.) Missing values: None Description: Game number Type: Numeric Values: Range 1 5 Missing values: None Description: Quarter game Type: Numeric Values: Range 1 4, including overtime (OT) Missing values: None Description: Time remaining quarter Type: Categorical Values: Various time values (e.g., 9:47, 0:00, etc.) Missing values: None Description: Description shot Type: Categorical Values: Various shot descriptions (e.g., “Kobe Bryant makes 4-foot two point shot”, “Kobe Bryant misses jumper”, etc.) Missing values: None Description: Whether shot made missed Type: Categorical Values: - H = Hit (made) M = Miss (missed) Missing values: None time description omitted brevity. dataset complete missing values. variables coded consistently. codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"where-to-find-it","dir":"Articles","previous_headings":"","what":"Where to find it","title":"Codebook for kobe_basket dataset","text":"Dataset name: kobe_basket Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for kobe_basket dataset","text":"dataset contains information Kobe Bryant’s basketball shots, including opponent, game details, shot description, whether shot made missed. dataset includes multiple observations 6 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for kobe_basket dataset","text":"Description: Opponent team Type: Categorical Values: Various team abbreviations (e.g., ORL, MIA, etc.) Missing values: None Description: Game number Type: Numeric Values: Range 1 5 Missing values: None Description: Quarter game Type: Numeric Values: Range 1 4, including overtime (OT) Missing values: None Description: Time remaining quarter Type: Categorical Values: Various time values (e.g., 9:47, 0:00, etc.) Missing values: None Description: Description shot Type: Categorical Values: Various shot descriptions (e.g., “Kobe Bryant makes 4-foot two point shot”, “Kobe Bryant misses jumper”, etc.) Missing values: None Description: Whether shot made missed Type: Categorical Values: - H = Hit (made) M = Miss (missed) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"vs","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"vs","title":"Codebook for kobe_basket dataset","text":"Description: Opponent team Type: Categorical Values: Various team abbreviations (e.g., ORL, MIA, etc.) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"game","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"game","title":"Codebook for kobe_basket dataset","text":"Description: Game number Type: Numeric Values: Range 1 5 Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"quarter","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"quarter","title":"Codebook for kobe_basket dataset","text":"Description: Quarter game Type: Numeric Values: Range 1 4, including overtime (OT) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"time","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"time","title":"Codebook for kobe_basket dataset","text":"Description: Time remaining quarter Type: Categorical Values: Various time values (e.g., 9:47, 0:00, etc.) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"description","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"description","title":"Codebook for kobe_basket dataset","text":"Description: Description shot Type: Categorical Values: Various shot descriptions (e.g., “Kobe Bryant makes 4-foot two point shot”, “Kobe Bryant misses jumper”, etc.) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"shot","dir":"Articles","previous_headings":"Codebook: Kobe Bryant Basketball Dataset","what":"shot","title":"Codebook for kobe_basket dataset","text":"Description: Whether shot made missed Type: Categorical Values: - H = Hit (made) M = Miss (missed) Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook for kobe_basket dataset","text":"time description omitted brevity.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for kobe_basket dataset","text":"dataset complete missing values. variables coded consistently.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_kobe.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for kobe_basket dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"codebook-nhanes-dataset","dir":"Articles","previous_headings":"","what":"Codebook: NHANES Dataset","title":"Codebook and example merging for NHANES Datasets","text":"Dataset names: PBCD_J.xpt INS_J.xpt single-page list download links codebooks. Direct download links CDC 2017-18 PBCD_J.xpt INS_J.xpt Backup download links GitHub PBCD_J.xpt INS_J.xpt Codebooks PBCD_J INS_J Option 1: Download datasets directly CDC. Note: seems get blocked browser webR run Option 2: Download datasets GitHub backup: need load merge, join, datasets single file. First, load using haven package can import data SAS, SPSS, STATA formats. Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error. can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures following command downloads reads dataset first line, joins dataset second line, joins result dataset third line. Success! want save merged nhanes2 object, use readr::write_csv something like . Take look dataset see : Note: running outside webR, save step downloading first, provide full URL instead filename. R data-loading functions can take URL filename. nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables. Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541 SEQN omitted brevity contains unique values observation. dataset missing values LBXBPB LBXIN columns. codebook drafted Microsoft Copilot edited Levi Waldron. kidding, Copilot helpful Codebook many weird issues downloading certain files webR. useful things Dataset Overview Variables sections, although even fix numbers incorrect output.","code":"download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/PBCD_J.xpt\",   destfile = \"PBCD_J.xpt\" ) download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/INS_J.xpt\",   destfile = \"INS_J.xpt\" )"},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"getting-the-data","dir":"Articles","previous_headings":"","what":"Getting the data","title":"Codebook and example merging for NHANES Datasets","text":"Option 1: Download datasets directly CDC. Note: seems get blocked browser webR run Option 2: Download datasets GitHub backup: need load merge, join, datasets single file. First, load using haven package can import data SAS, SPSS, STATA formats. Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error.","code":"download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/PBCD_J.xpt\",   destfile = \"PBCD_J.xpt\" ) download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/INS_J.xpt\",   destfile = \"INS_J.xpt\" )"},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"getting-and-joining-other-nhanes-datasets","dir":"Articles","previous_headings":"","what":"Getting and joining other NHANES datasets","title":"Codebook and example merging for NHANES Datasets","text":"can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures following command downloads reads dataset first line, joins dataset second line, joins result dataset third line. Success! want save merged nhanes2 object, use readr::write_csv something like . Take look dataset see : Note: running outside webR, save step downloading first, provide full URL instead filename. R data-loading functions can take URL filename.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook and example merging for NHANES Datasets","text":"nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"seqn","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"SEQN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"lbxbpb","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXBPB","title":"Codebook and example merging for NHANES Datasets","text":"Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"lbxin","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXIN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook and example merging for NHANES Datasets","text":"SEQN omitted brevity contains unique values observation.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook and example merging for NHANES Datasets","text":"dataset missing values LBXBPB LBXIN columns.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook and example merging for NHANES Datasets","text":"codebook drafted Microsoft Copilot edited Levi Waldron. kidding, Copilot helpful Codebook many weird issues downloading certain files webR. useful things Dataset Overview Variables sections, although even fix numbers incorrect output.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"codebook-nhanes-dataset","dir":"Articles","previous_headings":"","what":"Codebook: NHANES Dataset","title":"Codebook and example merging for NHANES Datasets","text":"Dataset names: PBCD_J.xpt INS_J.xpt single-page list download links codebooks. Direct download links CDC 2017-18 PBCD_J.xpt INS_J.xpt Backup download links GitHub PBCD_J.xpt INS_J.xpt Codebooks PBCD_J INS_J Option 1: Download datasets directly CDC. Note: seems get blocked browser webR run Option 2: Download datasets GitHub backup: need load merge, join, datasets single file. First, load using haven package can import data SAS, SPSS, STATA formats. Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error. can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded directly NHANES inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures take advantage ability haven’s data-loading functions read data directly URL. R data-loading functions can . following command downloads reads dataset first line, joins dataset second line, joins result dataset third line. Success! data files directly nhanes2 object without saving files locally. Use readr::write_csv something like want save data locally. Take look dataset see : nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables. Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541 SEQN omitted brevity contains unique values observation. dataset missing values LBXBPB LBXIN columns. codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"getting-the-data","dir":"Articles","previous_headings":"","what":"Getting the data","title":"Codebook and example merging for NHANES Datasets","text":"Option 1: Download datasets directly CDC. Note: seems get blocked browser webR run Option 2: Download datasets GitHub backup: need load merge, join, datasets single file. First, load using haven package can import data SAS, SPSS, STATA formats. Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"getting-and-joining-other-nhanes-datasets","dir":"Articles","previous_headings":"","what":"Getting and joining other NHANES datasets","title":"Codebook and example merging for NHANES Datasets","text":"can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded directly NHANES inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures take advantage ability haven’s data-loading functions read data directly URL. R data-loading functions can . following command downloads reads dataset first line, joins dataset second line, joins result dataset third line. Success! data files directly nhanes2 object without saving files locally. Use readr::write_csv something like want save data locally. Take look dataset see :","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook and example merging for NHANES Datasets","text":"nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"seqn","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"SEQN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"lbxbpb","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXBPB","title":"Codebook and example merging for NHANES Datasets","text":"Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"lbxin","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXIN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook and example merging for NHANES Datasets","text":"SEQN omitted brevity contains unique values observation.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook and example merging for NHANES Datasets","text":"dataset missing values LBXBPB LBXIN columns.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook and example merging for NHANES Datasets","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"codebook-nhanes-dataset","dir":"Articles","previous_headings":"","what":"Codebook: NHANES Dataset","title":"Codebook and example merging for NHANES Datasets","text":"Dataset names: PBCD_J.xpt INS_J.xpt single-page list download links codebooks. Direct download links CDC 2017-18 PBCD_J.xpt INS_J.xpt Backup download links GitHub PBCD_J.xpt INS_J.xpt Codebooks PBCD_J INS_J browsers prevent code downloading binary .xpt files (unless use CORS proxy), following use .csv conversion datasets can downloaded webR. running R webR (ie RStudio, Jupyter, another R client), can following directly .xpt files. Option 1: Download csv versions GitHub backup (xpt binary download can restricted browser webR) Option 2 (work normal R session webR) - Download xpt files directly CDC: need load merge, join, datasets single file. working original .xpt files, load using haven package can import data SAS, SPSS, STATA formats. example, However, webR ’ll use csv files downloaded : Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error. can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded directly NHANES inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures take advantage ability data-loading functions read data directly URL. haven, readr, base-R data-loading functions can . following code downloads reads dataset first line, joins dataset second line, joins result dataset third line. download directly CDC, ’re using webR: ’s version works webR: Success! data files directly nhanes2 object without saving files locally. Use readr::write_csv something like want save data locally. Take look dataset see : nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables. Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541 SEQN omitted brevity contains unique values observation. dataset missing values LBXBPB LBXIN columns. codebook drafted Microsoft Copilot edited Levi Waldron.","code":"download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/PBCD_J.xpt\",   destfile = \"PBCD_J.xpt\" ) download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/INS_J.xpt\",   destfile = \"INS_J.xpt\" ) library(haven) nhanesPb <- read_xpt(\"PBCD_J.xpt\") library(haven) library(dplyr) nhanes2 <- read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DEMO_L.xpt\") %>%   inner_join(read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DSQTOT_L.xpt\"), by = \"SEQN\") %>%   inner_join(read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/BPXO_L.xpt\"), by = \"SEQN\") library(readr) library(dplyr) Attaching package: 'dplyr' The following objects are masked from 'package:stats':      filter, lag The following objects are masked from 'package:base':      intersect, setdiff, setequal, union nhanes2 <- read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/DEMO_L.csv\") %>%   inner_join(read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/DSQTOT_L.csv\"), by = \"SEQN\") %>%   inner_join(read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/BPXO_L.csv\"), by = \"SEQN\") Rows: 11933 Columns: 27 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" dbl (27): SEQN, SDDSRVYR, RIDSTATR, RIAGENDR, RIDAGEYR, RIDAGEMN, RIDRETH1, ...  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Warning: One or more parsing issues, call `problems()` on your data frame for details, e.g.:   dat <- vroom(...)   problems(dat) Rows: 8860 Columns: 40 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" dbl (39): SEQN, WTDRD1, DSDCOUNT, DSDANCNT, DSD010, DSD010AN, DSQTKCAL, DSQT... lgl  (1): DSQTCAFF  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Rows: 7801 Columns: 12 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" chr  (1): BPAOARM dbl (11): SEQN, BPAOCSZ, BPXOSY1, BPXODI1, BPXOSY2, BPXODI2, BPXOSY3, BPXODI...  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"getting-the-data","dir":"Articles","previous_headings":"","what":"Getting the data","title":"Codebook and example merging for NHANES Datasets","text":"browsers prevent code downloading binary .xpt files (unless use CORS proxy), following use .csv conversion datasets can downloaded webR. running R webR (ie RStudio, Jupyter, another R client), can following directly .xpt files. Option 1: Download csv versions GitHub backup (xpt binary download can restricted browser webR) Option 2 (work normal R session webR) - Download xpt files directly CDC: need load merge, join, datasets single file. working original .xpt files, load using haven package can import data SAS, SPSS, STATA formats. example, However, webR ’ll use csv files downloaded : Now join two datasets, matching partipant ID column SEQN. uses full_join incredible user-friendly powerful join functions dplyr package. full_join means partipants SEQN column maintained, even participant exists one two datasets. options, example inner_join keeps participants present datasets, left_join keeps partipants present first dataset (first dataset whichever specify first argument join function). See dplyr help two table verbs information. Finally, may want simplify dataset using dplyr::select select columns intend use. don’t need dplyr:: like include forgot library(dplyr) library(tidyverse) accidentally use select base R, different usage give error.","code":"download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/PBCD_J.xpt\",   destfile = \"PBCD_J.xpt\" ) download.file(   \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/INS_J.xpt\",   destfile = \"INS_J.xpt\" ) library(haven) nhanesPb <- read_xpt(\"PBCD_J.xpt\")"},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"getting-and-joining-other-nhanes-datasets","dir":"Articles","previous_headings":"","what":"Getting and joining other NHANES datasets","title":"Codebook and example merging for NHANES Datasets","text":"can join two datasets like join third dataset, , repeating many times want. Just make sure use participant ID (SEQN) NHANES cycle. ’s shorthand join several 2021-23 datasets, downloaded directly NHANES inner_joined keep participants data available. datasets : Demographic Variables Sample Weights Dietary Supplement Use 30-day - Total Dietary Supplements Body Measures take advantage ability data-loading functions read data directly URL. haven, readr, base-R data-loading functions can . following code downloads reads dataset first line, joins dataset second line, joins result dataset third line. download directly CDC, ’re using webR: ’s version works webR: Success! data files directly nhanes2 object without saving files locally. Use readr::write_csv something like want save data locally. Take look dataset see :","code":"library(haven) library(dplyr) nhanes2 <- read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DEMO_L.xpt\") %>%   inner_join(read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/DSQTOT_L.xpt\"), by = \"SEQN\") %>%   inner_join(read_xpt(\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2021/DataFiles/BPXO_L.xpt\"), by = \"SEQN\") library(readr) library(dplyr) Attaching package: 'dplyr' The following objects are masked from 'package:stats':      filter, lag The following objects are masked from 'package:base':      intersect, setdiff, setequal, union nhanes2 <- read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/DEMO_L.csv\") %>%   inner_join(read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/DSQTOT_L.csv\"), by = \"SEQN\") %>%   inner_join(read_csv(\"https://github.com/CUNY-epibios/PUBH614/raw/refs/heads/main/datasets/BPXO_L.csv\"), by = \"SEQN\") Rows: 11933 Columns: 27 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" dbl (27): SEQN, SDDSRVYR, RIDSTATR, RIAGENDR, RIDAGEYR, RIDAGEMN, RIDRETH1, ...  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Warning: One or more parsing issues, call `problems()` on your data frame for details, e.g.:   dat <- vroom(...)   problems(dat) Rows: 8860 Columns: 40 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" dbl (39): SEQN, WTDRD1, DSDCOUNT, DSDANCNT, DSD010, DSD010AN, DSQTKCAL, DSQT... lgl  (1): DSQTCAFF  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Rows: 7801 Columns: 12 ── Column specification ──────────────────────────────────────────────────────── Delimiter: \",\" chr  (1): BPAOARM dbl (11): SEQN, BPAOCSZ, BPXOSY1, BPXODI1, BPXOSY2, BPXODI2, BPXOSY3, BPXODI...  ℹ Use `spec()` to retrieve the full column specification for this data. ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook and example merging for NHANES Datasets","text":"nhanes dataset contains three variables 2017-18 NHANES dataset. dataset includes 8,366 observations 3 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0 Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482 Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"seqn","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"SEQN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Sequence number Type: Numeric Values: Various sequence numbers, e.g., 93703, 93704, etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"lbxbpb","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXBPB","title":"Codebook and example merging for NHANES Datasets","text":"Description: Blood lead level (ug/dL) Type: Numeric Values: Various blood lead levels, e.g., 2.98, 0.74, etc. Missing values: 1,482","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"lbxin","dir":"Articles","previous_headings":"Codebook: NHANES Dataset","what":"LBXIN","title":"Codebook and example merging for NHANES Datasets","text":"Description: Insulin level (uU/mL) Type: Numeric Values: Various insulin levels, e.g., 9.72, 5.28, etc. Missing values: 5,541","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook and example merging for NHANES Datasets","text":"SEQN omitted brevity contains unique values observation.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook and example merging for NHANES Datasets","text":"dataset missing values LBXBPB LBXIN columns.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nhanes_csv2.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook and example merging for NHANES Datasets","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"codebook-nyc-flights-dataset","dir":"Articles","previous_headings":"","what":"Codebook: NYC Flights Dataset","title":"Codebook for NYC Flights Dataset","text":"Dataset name: nycflights Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Option 1: load dataset openintro package: Option 2: load dataset manually dataset contains information flights departed NYC 2013. dataset includes 500 observations 16 variables. Description: Year flight Type: Numeric Values: 2013 Missing values: 0 Description: Month flight Type: Numeric Values: 1 12 Missing values: 0 Description: Day flight Type: Numeric Values: 1 31 Missing values: 0 Description: Departure time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0 Description: Departure delay (minutes) Type: Numeric Values: -21 1,301 Missing values: 0 Description: Arrival time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0 Description: Arrival delay (minutes) Type: Numeric Values: -73 1,272 Missing values: 0 Description: Carrier code Type: Categorical Values: Various carrier codes, e.g. 9E, AA, , etc. Missing values: 0 Description: Tail number plane Type: Categorical Values: Various tail numbers, e.g. N0EGMQ, N10156, etc. Missing values: 0 Description: Flight number Type: Numeric Values: 1 6,181 Missing values: 0 Description: Origin airport Type: Categorical Values: JFK, LGA, EWR Missing values: 0 Description: Destination airport Type: Categorical Values: Various 3-letter destination codes, e.g. ABQ, ACK, ALB, etc. Missing values: 0 Description: Air time (minutes) Type: Numeric Values: 22 686 Missing values: 0 Description: Distance (miles) Type: Numeric Values: 94 4,983 Missing values: 0 Description: Scheduled departure hour Type: Numeric Values: 0 24 Missing values: 0 Description: Scheduled departure minute Type: Numeric Values: 0 59 Missing values: 0 tailnum omitted brevity contains 3,490 unique values (one individual airplane). dest omitted brevity contains 102 unique values. dataset missing values columns. Although flight coded numeric, considered categorical variable. codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for NYC Flights Dataset","text":"dataset contains information flights departed NYC 2013. dataset includes 500 observations 16 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for NYC Flights Dataset","text":"Description: Year flight Type: Numeric Values: 2013 Missing values: 0 Description: Month flight Type: Numeric Values: 1 12 Missing values: 0 Description: Day flight Type: Numeric Values: 1 31 Missing values: 0 Description: Departure time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0 Description: Departure delay (minutes) Type: Numeric Values: -21 1,301 Missing values: 0 Description: Arrival time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0 Description: Arrival delay (minutes) Type: Numeric Values: -73 1,272 Missing values: 0 Description: Carrier code Type: Categorical Values: Various carrier codes, e.g. 9E, AA, , etc. Missing values: 0 Description: Tail number plane Type: Categorical Values: Various tail numbers, e.g. N0EGMQ, N10156, etc. Missing values: 0 Description: Flight number Type: Numeric Values: 1 6,181 Missing values: 0 Description: Origin airport Type: Categorical Values: JFK, LGA, EWR Missing values: 0 Description: Destination airport Type: Categorical Values: Various 3-letter destination codes, e.g. ABQ, ACK, ALB, etc. Missing values: 0 Description: Air time (minutes) Type: Numeric Values: 22 686 Missing values: 0 Description: Distance (miles) Type: Numeric Values: 94 4,983 Missing values: 0 Description: Scheduled departure hour Type: Numeric Values: 0 24 Missing values: 0 Description: Scheduled departure minute Type: Numeric Values: 0 59 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"year","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"year","title":"Codebook for NYC Flights Dataset","text":"Description: Year flight Type: Numeric Values: 2013 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"month","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"month","title":"Codebook for NYC Flights Dataset","text":"Description: Month flight Type: Numeric Values: 1 12 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"day","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"day","title":"Codebook for NYC Flights Dataset","text":"Description: Day flight Type: Numeric Values: 1 31 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"dep_time","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"dep_time","title":"Codebook for NYC Flights Dataset","text":"Description: Departure time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"dep_delay","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"dep_delay","title":"Codebook for NYC Flights Dataset","text":"Description: Departure delay (minutes) Type: Numeric Values: -21 1,301 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"arr_time","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"arr_time","title":"Codebook for NYC Flights Dataset","text":"Description: Arrival time (HHMM format) Type: Numeric Values: 1 2,400 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"arr_delay","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"arr_delay","title":"Codebook for NYC Flights Dataset","text":"Description: Arrival delay (minutes) Type: Numeric Values: -73 1,272 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"carrier","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"carrier","title":"Codebook for NYC Flights Dataset","text":"Description: Carrier code Type: Categorical Values: Various carrier codes, e.g. 9E, AA, , etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"tailnum","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"tailnum","title":"Codebook for NYC Flights Dataset","text":"Description: Tail number plane Type: Categorical Values: Various tail numbers, e.g. N0EGMQ, N10156, etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"flight","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"flight","title":"Codebook for NYC Flights Dataset","text":"Description: Flight number Type: Numeric Values: 1 6,181 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"origin","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"origin","title":"Codebook for NYC Flights Dataset","text":"Description: Origin airport Type: Categorical Values: JFK, LGA, EWR Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"dest","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"dest","title":"Codebook for NYC Flights Dataset","text":"Description: Destination airport Type: Categorical Values: Various 3-letter destination codes, e.g. ABQ, ACK, ALB, etc. Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"air_time","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"air_time","title":"Codebook for NYC Flights Dataset","text":"Description: Air time (minutes) Type: Numeric Values: 22 686 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"distance","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"distance","title":"Codebook for NYC Flights Dataset","text":"Description: Distance (miles) Type: Numeric Values: 94 4,983 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"hour","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"hour","title":"Codebook for NYC Flights Dataset","text":"Description: Scheduled departure hour Type: Numeric Values: 0 24 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"minute","dir":"Articles","previous_headings":"Codebook: NYC Flights Dataset","what":"minute","title":"Codebook for NYC Flights Dataset","text":"Description: Scheduled departure minute Type: Numeric Values: 0 59 Missing values: 0","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"summary-statistics","dir":"Articles","previous_headings":"","what":"Summary Statistics","title":"Codebook for NYC Flights Dataset","text":"tailnum omitted brevity contains 3,490 unique values (one individual airplane). dest omitted brevity contains 102 unique values.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for NYC Flights Dataset","text":"dataset missing values columns. Although flight coded numeric, considered categorical variable.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_nycflights.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for NYC Flights Dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"codebook-small-cell-lung-cancer-dataset","dir":"Articles","previous_headings":"","what":"Codebook: Small-Cell Lung Cancer Dataset","title":"Codebook for small-cell lung cancer dataset","text":"Used : Lab 4b: logistic regression File name: Stats4- .csv Location: Available online https://media.githubusercontent.com/media/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Code load dataset R, ensure columns read factor type: dataset contains information small-cell lung cancer cases, including smoking status, cancer status, patient sex. dataset includes 209 observations 3 variables. Description: Smoking status patient Type: Binary (0/1) 0 = Non-smoker 1 = Smoker Missing values: None Description: Lung cancer status Type: Binary (0/1) 0 = lung cancer 1 = lung cancer Missing values: None Description: Biological sex patient Type: Binary (M/F) M = Male F = Female Missing values: None dataset complete missing values variables coded consistently smoke lungca use 0/1 coding sex coded using single-letter values (M/F) codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"where-to-find-it","dir":"Articles","previous_headings":"","what":"Where to find it","title":"Codebook for small-cell lung cancer dataset","text":"Used : Lab 4b: logistic regression File name: Stats4- .csv Location: Available online https://media.githubusercontent.com/media/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Code load dataset R, ensure columns read factor type:","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for small-cell lung cancer dataset","text":"dataset contains information small-cell lung cancer cases, including smoking status, cancer status, patient sex. dataset includes 209 observations 3 variables.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for small-cell lung cancer dataset","text":"Description: Smoking status patient Type: Binary (0/1) 0 = Non-smoker 1 = Smoker Missing values: None Description: Lung cancer status Type: Binary (0/1) 0 = lung cancer 1 = lung cancer Missing values: None Description: Biological sex patient Type: Binary (M/F) M = Male F = Female Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"smoke","dir":"Articles","previous_headings":"Codebook: Small-Cell Lung Cancer Dataset","what":"smoke","title":"Codebook for small-cell lung cancer dataset","text":"Description: Smoking status patient Type: Binary (0/1) 0 = Non-smoker 1 = Smoker Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"lungca","dir":"Articles","previous_headings":"Codebook: Small-Cell Lung Cancer Dataset","what":"lungca","title":"Codebook for small-cell lung cancer dataset","text":"Description: Lung cancer status Type: Binary (0/1) 0 = lung cancer 1 = lung cancer Missing values: None","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"sex","dir":"Articles","previous_headings":"Codebook: Small-Cell Lung Cancer Dataset","what":"sex","title":"Codebook for small-cell lung cancer dataset","text":"Description: Biological sex patient Type: Binary (M/F) M = Male F = Female Missing values: None","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for small-cell lung cancer dataset","text":"dataset complete missing values variables coded consistently smoke lungca use 0/1 coding sex coded using single-letter values (M/F)","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_sclc.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for small-cell lung cancer dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"codebook-youth-risk-behavior-surveillance-system-yrbss-dataset","dir":"Articles","previous_headings":"","what":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Dataset name: yrbss Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Data source: https://www.cdc.gov/yrbs/data/index.html Option 1: load dataset openintro package: Option 2: load dataset manually dataset contains information Youth Risk Behavior Surveillance System (YRBSS), including demographic details, health behaviors, related information. dataset includes 13,583 observations 13 variables. openintro package also provides sample n=100 dataset titled yrbss_samp. Description: Age respondent Type: Numeric Values: Range 12 18 Missing values: 77 Description: Gender respondent Type: Categorical Values: male, female Missing values: 12 Description: Grade respondent Type: Categorical Values: Range 9 12, plus “” Missing values: 79 Description: Hispanic ethnicity respondent Type: Categorical Values: hispanic, Missing values: 231 Description: Race respondent Type: Categorical Values: Various race categories (e.g., Black African American, White, Asian, etc.) Missing values: 2,805 Description: Height respondent meters Type: Numeric Values: Range 1.27 2.11 meters Missing values: 1,004 Description: Weight respondent kilograms Type: Numeric Values: Range 29.94 180.99 kilograms Missing values: 1,004 Description: Frequency wearing helmet past 12 months Type: Categorical Values: never, rarely, sometimes, time, always, ride Missing values: 311 Description: Frequency texting driving past 30 days Type: Categorical Values: never, 0, 1-2, 3-5, 6-9, 10-19, 20-29, 30, drive Missing values: 918 Description: Number days physically active past 7 days Type: Numeric Values: Range 0 7 days Missing values: 273 Description: Hours spent watching TV per school day Type: Categorical Values: watch, <1, 1, 2, 3, 4, 5+ Missing values: 338 Description: Number days strength training past 7 days Type: Numeric Values: Range 0 7 days Missing values: 1,176 Description: Hours sleep school night Type: Categorical Values: Range <5 10+ hours Missing values: 1,248 dataset missing values multiple columns. text_while_driving_30d hours_tv_per_school_day school_night_hours_sleep codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"where-to-find-it","dir":"Articles","previous_headings":"","what":"Where to find it","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Dataset name: yrbss Location: Loaded automatically openintro package loaded. Also available online https://github.com/CUNY-epibios/PUBH614/tree/main/datasets Download dataset now Data source: https://www.cdc.gov/yrbs/data/index.html Option 1: load dataset openintro package: Option 2: load dataset manually","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"dataset-overview","dir":"Articles","previous_headings":"","what":"Dataset Overview","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"dataset contains information Youth Risk Behavior Surveillance System (YRBSS), including demographic details, health behaviors, related information. dataset includes 13,583 observations 13 variables. openintro package also provides sample n=100 dataset titled yrbss_samp.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"variables","dir":"Articles","previous_headings":"","what":"Variables","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Age respondent Type: Numeric Values: Range 12 18 Missing values: 77 Description: Gender respondent Type: Categorical Values: male, female Missing values: 12 Description: Grade respondent Type: Categorical Values: Range 9 12, plus “” Missing values: 79 Description: Hispanic ethnicity respondent Type: Categorical Values: hispanic, Missing values: 231 Description: Race respondent Type: Categorical Values: Various race categories (e.g., Black African American, White, Asian, etc.) Missing values: 2,805 Description: Height respondent meters Type: Numeric Values: Range 1.27 2.11 meters Missing values: 1,004 Description: Weight respondent kilograms Type: Numeric Values: Range 29.94 180.99 kilograms Missing values: 1,004 Description: Frequency wearing helmet past 12 months Type: Categorical Values: never, rarely, sometimes, time, always, ride Missing values: 311 Description: Frequency texting driving past 30 days Type: Categorical Values: never, 0, 1-2, 3-5, 6-9, 10-19, 20-29, 30, drive Missing values: 918 Description: Number days physically active past 7 days Type: Numeric Values: Range 0 7 days Missing values: 273 Description: Hours spent watching TV per school day Type: Categorical Values: watch, <1, 1, 2, 3, 4, 5+ Missing values: 338 Description: Number days strength training past 7 days Type: Numeric Values: Range 0 7 days Missing values: 1,176 Description: Hours sleep school night Type: Categorical Values: Range <5 10+ hours Missing values: 1,248","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"age","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"age","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Age respondent Type: Numeric Values: Range 12 18 Missing values: 77","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"gender","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"gender","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Gender respondent Type: Categorical Values: male, female Missing values: 12","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"grade","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"grade","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Grade respondent Type: Categorical Values: Range 9 12, plus “” Missing values: 79","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"hispanic","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"hispanic","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Hispanic ethnicity respondent Type: Categorical Values: hispanic, Missing values: 231","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"race","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"race","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Race respondent Type: Categorical Values: Various race categories (e.g., Black African American, White, Asian, etc.) Missing values: 2,805","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"height","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"height","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Height respondent meters Type: Numeric Values: Range 1.27 2.11 meters Missing values: 1,004","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"weight","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"weight","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Weight respondent kilograms Type: Numeric Values: Range 29.94 180.99 kilograms Missing values: 1,004","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"helmet_12m","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"helmet_12m","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Frequency wearing helmet past 12 months Type: Categorical Values: never, rarely, sometimes, time, always, ride Missing values: 311","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"text_while_driving_30d","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"text_while_driving_30d","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Frequency texting driving past 30 days Type: Categorical Values: never, 0, 1-2, 3-5, 6-9, 10-19, 20-29, 30, drive Missing values: 918","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"physically_active_7d","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"physically_active_7d","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Number days physically active past 7 days Type: Numeric Values: Range 0 7 days Missing values: 273","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"hours_tv_per_school_day","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"hours_tv_per_school_day","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Hours spent watching TV per school day Type: Categorical Values: watch, <1, 1, 2, 3, 4, 5+ Missing values: 338","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"strength_training_7d","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"strength_training_7d","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Number days strength training past 7 days Type: Numeric Values: Range 0 7 days Missing values: 1,176","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"school_night_hours_sleep","dir":"Articles","previous_headings":"Codebook: Youth Risk Behavior Surveillance System (YRBSS) Dataset","what":"school_night_hours_sleep","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"Description: Hours sleep school night Type: Categorical Values: Range <5 10+ hours Missing values: 1,248","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"data-quality-notes","dir":"Articles","previous_headings":"","what":"Data Quality Notes","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"dataset missing values multiple columns. text_while_driving_30d hours_tv_per_school_day school_night_hours_sleep","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/articles/dataset_yrbss.html","id":"acknowledgements","dir":"Articles","previous_headings":"","what":"Acknowledgements","title":"Codebook for Youth Risk Behavior Surveillance System dataset","text":"codebook drafted Microsoft Copilot edited Levi Waldron.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Levi Waldron. Author, maintainer.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Waldron L (2025). PUBH614: Executable R Labs. R package version 1.0, https://cuny-epibios.github.io/PUBH614.","code":"@Manual{,   title = {PUBH614: Executable R Labs},   author = {Levi Waldron},   year = {2025},   note = {R package version 1.0},   url = {https://cuny-epibios.github.io/PUBH614}, }"},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick-start","title":"Executable R Labs","text":"Use menu bars : OpenIntro Labs: Labs OpenIntro Statistics Labs: Labs sources Datasets: Codebooks datasets used labs Exercises: contains blank workbook running R menus can run R directly web browser. running browser, remote server, can run offline. can also download code run R environment.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"about-wasm-and-webr","dir":"","previous_headings":"","what":"About WASM and webR","title":"Executable R Labs","text":"labs use WASM (WebAssembly) webR provide user-friendly alternative running R directly browser. approach eliminates need local installation Cloud service, allows interactive coding visualization within browser environment. Running R web browser can sometimes lead issues work saved: Data stored browser’s local storage, separated local filesystem. means data code persistent across sessions, lose work close browser. can print page save work, copy code local text file. Performance Limitations: Browser-based execution may slower compared local execution. Even powerful computer, browser likely supports 4GB memory WebAssembly applications. Browser Compatibility: Ensure using modern browser supports WebAssembly, current version Chrome, Firefox, Safari, Edge.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"about-openintro-labs","dir":"","previous_headings":"","what":"About OpenIntro Labs","title":"Executable R Labs","text":"OpenIntro labs (see OpenIntro labs tab ) developed OpenIntro Statistics adapted use web Levi Waldron CUNY SPH. OpenIntro Labs promote understanding application statistics applied data analysis. Labs titled based topic area, correspond particular chapters three versions OpenIntro Statistics, free open-source textbook. textbook well original versions labs can found https://www.openintro.org/book/ims/.","code":""},{"path":[]},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"what-are-r-and-cran","dir":"","previous_headings":"","what":"What are R and CRAN?","title":"Executable R Labs","text":"R powerful programming language environment designed statistical computing graphics. widely used among statisticians data scientists data analysis visualization. CRAN (Comprehensive R Archive Network) repository hosts R packages, collections R functions, data, compiled code extend capabilities R. CRAN hosts 20,000 active packages, libraries, adding extra functionality R.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"how-is-r-different-from-sas-and-spss","dir":"","previous_headings":"What are R and CRAN?","what":"How is R Different from SAS and SPSS?","title":"Executable R Labs","text":"R open-source language, means free use large community contributing development. Unlike SAS SPSS, commercial software licensing fees, R offers vast array free add-libraries various statistical techniques. R valued academic research environments extensibility active community support.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"rstudio-a-powerful-ide-for-r","dir":"","previous_headings":"","what":"RStudio: A Powerful IDE for R","title":"Executable R Labs","text":"RStudio popular integrated development environment (IDE) running R. provides feature-rich complex interface data analysis software development R. RStudio powerful, learning curve, especially new programming R. can install R RStudio free computer .","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"cloud-services-for-running-r","dir":"","previous_headings":"","what":"Cloud Services for Running R","title":"Executable R Labs","text":"several cloud services offer free tiers running R, making accessible without need local installation. offer persistent storage resources running R browser. posit.cloud cloud-based service Posit (formerly RStudio) allows run R RStudio using browser. free tier limited resources sufficient running labs course. Note: whereas https://cuny-epibios.github.io/PUBH614/ runs code browser actually running computer, posit.cloud cloud services run code remote server. Google Colab another cloud-based service uses Jupyter notebooks, alternative system running code interactively. Jupyter notebooks widely used data science machine learning, less feature-rich simpler use RStudio. Google Colab provides generous resources free tier cheaper paid tiers posit.cloud, makes use Google Drive storage.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"reporting-issues","dir":"","previous_headings":"","what":"Reporting Issues","title":"Executable R Labs","text":"encounter issues, notice errors problems, suggestions improvement, please let Levi Waldron potential contributors know opening issue.","code":""},{"path":"https://cuny-epibios.github.io/PUBH614/index.html","id":"building-this-site","dir":"","previous_headings":"","what":"Building this site","title":"Executable R Labs","text":"Datasets labs stored source code . Test individual labs command-line: Rebuild entire site R: Modify website layout _pkgdown.yml, modify custom css pkgdown/custom.css. work licensed Creative Commons Attribution-ShareAlike 4.0 International License.","code":"quarto render vignettes/01_intro_to_r.qmd pkgdown::build_site()"},{"path":"https://cuny-epibios.github.io/PUBH614/lab_source_style_guide.html","id":null,"dir":"","previous_headings":"","what":"Lab Style Guide","title":"Lab Style Guide","text":"Section titles formatted header 2, ##, followed blank line. Exercises ordered lists (1., 2., 3., …), lazy lists (1., 1., 1., …) two spaces dot (one space numbers > 9, < 100). Subsequent lines hanging-indented four spaces. questions unordered lists (-, -, -, …) three spaces following -. nested lists, see OYO lab 6 example preferred method. lists items followed blank line. Wrap lines, text code, 80 characters. counter can found lower left corner editor. Long urls strings segmented can overflow can lines code become confusing broken . -text numbers basic math operators marked . Latex used -line mathematical variables (e.g. $nS, $p$) complex symbols. Full equations displayed separate line \\[ \\]. -text code marked backticks. Force line break backslash \\\\. OYO section offset horizontal rule precedes . , use * * *. Don’t embed links text. : “BRFSS Web site ([http://www.cdc.gov/brfss] (http://www.cdc.gov/brfss))…”. : “[BRFSS Web site] (http://www.cdc.gov/brfss)…”. teachers print lab , want links visible. superscripts used text, use HTML instead Latex: th","code":""}]
